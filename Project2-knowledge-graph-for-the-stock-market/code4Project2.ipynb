{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Knowledge Graph Using Information Retrieval\n",
    "This project combines Named Entity Recognition, dependency syntactic parsing, Entity Disambiguation, Entity Resolution, NoSQL(graph database, Noe4j, cypher language), etc. to build \n",
    "a knowledge graph. Our goal is to use NLP tools to analyze many news data crawling from the website about list companies, find the latent relationships among different entities and build a knowledge graph, which will guide our future decisions. Here, we mainly focus on the equity transaction relationships. The organization of the project can be summarized as follows:\n",
    "1. entity resolution,\n",
    "2. named entity recognition\n",
    "3. relation extraction\n",
    "4. build a classifier to recognize the relationships in the test dataset\n",
    "5. create a graph database using NoSQL to store the relationships\n",
    "6. entity disambiguation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entity Resolution¶\n",
    "We need to unify different names under the same entity and extract the main contents. For example, we could omit the suffix, locations, and business scopes.\n",
    "Data sets are provided as follows:\n",
    "1. company_suffix.txt: common suffixes of companies\n",
    "2. company_business_scope.txt: standard business scopes of companies\n",
    "3. co_Province_Dim.txt: a dictionary of province\n",
    "4. co_City_Dim.txt: a dictionary of city\n",
    "5. stopwords.txt: stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jieba\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import re\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "dict_entity_name_unify = defaultdict(lambda:\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_extract(input_str,stop_word,d_4_delete,d_city_province):\n",
    "    \"\"\"\n",
    "    retrive entity from input name, and build dict\n",
    "    {\"entity name\": |\"full name1\"|\"full name2\"}\n",
    "    \"\"\"\n",
    "    seg = pseg.cut(input_str)\n",
    "    seg_lst = remove_word(seg,stop_word,d_4_delete)\n",
    "    seg_lst = city_prov_ahead(seg_lst,d_city_province)\n",
    "    result = ''.join(seg_lst)\n",
    "    if result != input_str:\n",
    "        dict_entity_name_unify[result] = dict_entity_name_unify[result] + \"|\" + input_str     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_prov_ahead(seg,d_city_province):\n",
    "    \"\"\"\n",
    "    move the location description to the front part of the strings\n",
    "    \"\"\"\n",
    "    city_prov_lst = []\n",
    "    for word in seg:\n",
    "        if word in d_city_province:\n",
    "            city_prov_lst.append(word)\n",
    "    seg_lst = [word for word in seg if word not in city_prov_lst]\n",
    "    return city_prov_lst+seg_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word(seg,stop_word,d_4_delete):\n",
    "    \"\"\"\n",
    "    remove stop words and words in predefinited deleting set\n",
    "    \"\"\"\n",
    "    filter_stop_word = [word for word, flag in seg if word not in stop_word]\n",
    "    seg_lst = [word for word in filter_stop_word if word not in d_4_delete]\n",
    "    return seg_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_initial():\n",
    "    \"\"\"\n",
    "    load text data\n",
    "    \"\"\"\n",
    "    fr1 = open(r\"../data/dict/co_City_Dim.txt\", encoding='utf-8')\n",
    "    fr2 = open(r\"../data/dict/co_Province_Dim.txt\", encoding='utf-8')\n",
    "    fr3 = open(r\"../data/dict/company_business_scope.txt\", encoding='utf-8')\n",
    "    fr4 = open(r\"../data/dict/company_suffix.txt\", encoding='utf-8')\n",
    "    \n",
    "    lines1 = fr1.readlines()\n",
    "    d_4_delete = []\n",
    "    d_city_province = [re.sub(r'(\\r|\\n)*','',line) for line in lines1]\n",
    "\n",
    "    lines2 = fr2.readlines()\n",
    "    l2_tmp = [re.sub(r'(\\r|\\n)*','',line) for line in lines2]\n",
    "    d_city_province.extend(l2_tmp)\n",
    "\n",
    "    lines4 = fr4.readlines()\n",
    "    l4_tmp = [re.sub(r'(\\r|\\n)*','',line) for line in lines4]\n",
    "    d_4_delete.extend(l4_tmp)\n",
    "\n",
    "    fr = open(r'../data/dict/stopwords.txt', encoding='utf-8')   \n",
    "    stop_word = fr.readlines()\n",
    "    stop_word_after = [re.sub(r'(\\r|\\n)*','',stop_word[i]) for i in range(len(stop_word))]\n",
    "    return d_4_delete,stop_word_after,d_city_province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.174 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "河北银行\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "d_4_delete,stop_word,d_city_province = my_initial()\n",
    "input_str = \"河北银行股份有限公司\"\n",
    "lst = main_extract(input_str,stop_word,d_4_delete,d_city_province)\n",
    "company_name = ''.join(lst)  \n",
    "print(company_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Named Entity Recognition\n",
    "Here I use an open-source tool named FoolNLTK to do named entity recognition.\n",
    "FoolNLTK is built based bi-lstm CRF framework.\n",
    "data is from data/train_data.csv and data/test_data.csv\n",
    "which is crawled from the news of the Listed companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "      <th>member1</th>\n",
       "      <th>member2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6461</td>\n",
       "      <td>与本公司关系:受同一公司控制 2，杭州富生电器有限公司企业类型: 有限公司注册地址: 富阳市...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2111</td>\n",
       "      <td>三、关联交易标的基本情况 1、交易标的基本情况 公司名称:红豆集团财务有限公司 公司地址:无...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9603</td>\n",
       "      <td>2016年协鑫集成科技股份有限公司向瑞峰（张家港）光伏科技有限公司支付设备款人民币4，515...</td>\n",
       "      <td>1</td>\n",
       "      <td>协鑫集成科技股份有限公司</td>\n",
       "      <td>瑞峰（张家港）光伏科技有限公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3456</td>\n",
       "      <td>证券代码:600777 证券简称:新潮实业 公告编号:2015-091 烟台新潮实业股份有限...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8844</td>\n",
       "      <td>本集团及广发证券股份有限公司持有辽宁成大股份有限公司股票的本期变动系买卖一揽子沪深300指数...</td>\n",
       "      <td>1</td>\n",
       "      <td>广发证券股份有限公司</td>\n",
       "      <td>辽宁成大股份有限公司</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           sentence  tag       member1  \\\n",
       "0  6461  与本公司关系:受同一公司控制 2，杭州富生电器有限公司企业类型: 有限公司注册地址: 富阳市...    0             0   \n",
       "1  2111  三、关联交易标的基本情况 1、交易标的基本情况 公司名称:红豆集团财务有限公司 公司地址:无...    0             0   \n",
       "2  9603  2016年协鑫集成科技股份有限公司向瑞峰（张家港）光伏科技有限公司支付设备款人民币4，515...    1  协鑫集成科技股份有限公司   \n",
       "3  3456  证券代码:600777 证券简称:新潮实业 公告编号:2015-091 烟台新潮实业股份有限...    0             0   \n",
       "4  8844  本集团及广发证券股份有限公司持有辽宁成大股份有限公司股票的本期变动系买卖一揽子沪深300指数...    1    广发证券股份有限公司   \n",
       "\n",
       "           member2  \n",
       "0                0  \n",
       "1                0  \n",
       "2  瑞峰（张家港）光伏科技有限公司  \n",
       "3                0  \n",
       "4       辽宁成大股份有限公司  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "train_data = pd.read_csv('../data/info_extract/train_data.csv', encoding = 'gb2312', header=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is labelled by hand. Tag = 1 means that there exits two entities in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9259</td>\n",
       "      <td>2015年1月26日，多氟多化工股份有限公司与李云峰先生签署了《附条件生效的股份认购合同》</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9136</td>\n",
       "      <td>2、2016年2月5日，深圳市新纶科技股份有限公司与侯毅先</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>2015年10月26日，山东华鹏玻璃股份有限公司与张德华先生签署了附条件生效条件的《股份认购合同》</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9041</td>\n",
       "      <td>2、2015年12月31日，印纪娱乐传媒股份有限公司与肖文革签订了《印纪娱乐传媒股份有限公司...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10041</td>\n",
       "      <td>一、金发科技拟与熊海涛女士签订《股份转让协议》，协议约定：以每股1.0509元的收购价格，收...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           sentence\n",
       "0   9259      2015年1月26日，多氟多化工股份有限公司与李云峰先生签署了《附条件生效的股份认购合同》\n",
       "1   9136                      2、2016年2月5日，深圳市新纶科技股份有限公司与侯毅先\n",
       "2    220  2015年10月26日，山东华鹏玻璃股份有限公司与张德华先生签署了附条件生效条件的《股份认购合同》\n",
       "3   9041  2、2015年12月31日，印纪娱乐传媒股份有限公司与肖文革签订了《印纪娱乐传媒股份有限公司...\n",
       "4  10041  一、金发科技拟与熊海涛女士签订《股份转让协议》，协议约定：以每股1.0509元的收购价格，收..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../data/info_extract/test_data.csv', encoding = 'gb2312', header=0)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I need to identify the entities in each sentence, and then replace these entities with special marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import fool\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "test_data['ner']=None\n",
    "ner_id = 1001\n",
    "ner_dict_new = defaultdict(lambda:0)  \n",
    "ner_dict_reverse_new = defaultdict(lambda:\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9259</td>\n",
       "      <td>2015年1月26日，多氟多化工股份有限公司与李云峰先生签署了《附条件生效的股份认购合同》</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9136</td>\n",
       "      <td>2、2016年2月5日，深圳市新纶科技股份有限公司与侯毅先</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>2015年10月26日，山东华鹏玻璃股份有限公司与张德华先生签署了附条件生效条件的《股份认购合同》</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9041</td>\n",
       "      <td>2、2015年12月31日，印纪娱乐传媒股份有限公司与肖文革签订了《印纪娱乐传媒股份有限公司...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10041</td>\n",
       "      <td>一、金发科技拟与熊海涛女士签订《股份转让协议》，协议约定：以每股1.0509元的收购价格，收...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>9503</td>\n",
       "      <td>近日，该子公司已完成工商注册登记手续，并领取了南京市工商行政管理局颁发的&lt;企业法人营业执照&gt;...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>4689</td>\n",
       "      <td>(二)本次交易构成关联交易正元投资拟认购金额不低于 13 亿元且不低于本次配套融资总额的 2...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1772</td>\n",
       "      <td>证券代码:600225 证券简称:天津松江 公告编号:临 2015-118 天津松江股份有限...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>9021</td>\n",
       "      <td>2015年3月31日，湖南天润数字娱乐文化传媒股份有限公司与广东恒润互兴资产管理有限公司签署...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>4770</td>\n",
       "      <td>三、本公司不会利用对西水股份控制关系损害西水股份及其他股东 (特别是中小股东)的合法权益。</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           sentence   ner\n",
       "0     9259      2015年1月26日，多氟多化工股份有限公司与李云峰先生签署了《附条件生效的股份认购合同》  None\n",
       "1     9136                      2、2016年2月5日，深圳市新纶科技股份有限公司与侯毅先  None\n",
       "2      220  2015年10月26日，山东华鹏玻璃股份有限公司与张德华先生签署了附条件生效条件的《股份认购合同》  None\n",
       "3     9041  2、2015年12月31日，印纪娱乐传媒股份有限公司与肖文革签订了《印纪娱乐传媒股份有限公司...  None\n",
       "4    10041  一、金发科技拟与熊海涛女士签订《股份转让协议》，协议约定：以每股1.0509元的收购价格，收...  None\n",
       "..     ...                                                ...   ...\n",
       "414   9503  近日，该子公司已完成工商注册登记手续，并领取了南京市工商行政管理局颁发的<企业法人营业执照>...  None\n",
       "415   4689  (二)本次交易构成关联交易正元投资拟认购金额不低于 13 亿元且不低于本次配套融资总额的 2...  None\n",
       "416   1772  证券代码:600225 证券简称:天津松江 公告编号:临 2015-118 天津松江股份有限...  None\n",
       "417   9021  2015年3月31日，湖南天润数字娱乐文化传媒股份有限公司与广东恒润互兴资产管理有限公司签署...  None\n",
       "418   4770      三、本公司不会利用对西水股份控制关系损害西水股份及其他股东 (特别是中小股东)的合法权益。  None\n",
       "\n",
       "[419 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/fool/predictor.py:32: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/fool/predictor.py:33: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hugo/anaconda3/envs/my_env/lib/python3.7/site-packages/fool/predictor.py:53: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words, ners = fool.analysis(test_data.iloc[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2015年', 't'),\n",
       " ('1月', 't'),\n",
       " ('26日', 't'),\n",
       " ('，', 'wd'),\n",
       " ('多', 'a'),\n",
       " ('氟', 'n'),\n",
       " ('多', 'a'),\n",
       " ('化工', 'n'),\n",
       " ('股份', 'n'),\n",
       " ('有限公司', 'n'),\n",
       " ('与', 'p'),\n",
       " ('李云峰', 'nr'),\n",
       " ('先生', 'n'),\n",
       " ('签署', 'v'),\n",
       " ('了', 'y'),\n",
       " ('《', 'wkz'),\n",
       " ('附', 'v'),\n",
       " ('条件', 'n'),\n",
       " ('生效', 'vi'),\n",
       " ('的', 'ude'),\n",
       " ('股份', 'n'),\n",
       " ('认购', 'v'),\n",
       " ('合同', 'n'),\n",
       " ('》', 'wky')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 10, 'time', '2015年1月26日'),\n",
       " (11, 22, 'company', '多氟多化工股份有限公司'),\n",
       " (23, 26, 'person', '李云峰')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ners[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 419/419 [00:34<00:00, 12.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in trange(len(test_data)):\n",
    "    sentence = copy(test_data.iloc[i, 1])\n",
    "    words, ners = fool.analysis(sentence)\n",
    "    for start, end, ner_type, ner_name in ners[0]:\n",
    "        if ner_type == 'company' or ner_type == 'person':\n",
    "            company_main_name = main_extract(ner_name, stop_word, d_4_delete, d_city_province)\n",
    "#             company_main_name = ''.join(lst) \n",
    "            if company_main_name not in ner_dict_new:\n",
    "                ner_id += 1\n",
    "                ner_dict_new[company_main_name] = ner_id\n",
    "            sentence = sentence[:start] + ' ner_' + str(ner_dict_new[company_main_name]) + '_ ' + sentence[end - 1:]\n",
    "    test_data.iloc[i, -1] = sentence\n",
    "X_test = test_data[['ner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9259</td>\n",
       "      <td>2015年1月26日，多氟多化工股份有限公司与李云峰先生签署了《附条件生效的股份认购合同》</td>\n",
       "      <td>2015年1月26日， ner_1002_ 司 ner_1003_ 云峰先生签署了《附条件生...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9136</td>\n",
       "      <td>2、2016年2月5日，深圳市新纶科技股份有限公司与侯毅先</td>\n",
       "      <td>2、2016年2月5日， ner_1004_ 司与侯 ner_1005_ 先</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>2015年10月26日，山东华鹏玻璃股份有限公司与张德华先生签署了附条件生效条件的《股份认购合同》</td>\n",
       "      <td>2015年10月26日， ner_1006_ 司与 ner_1007_ 华先生签署了附条件生...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9041</td>\n",
       "      <td>2、2015年12月31日，印纪娱乐传媒股份有限公司与肖文革签订了《印纪娱乐传媒股份有限公司...</td>\n",
       "      <td>2、2015年12月31日， ner_1008_ 司与 ner_1009_ 革签订了《印纪娱...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10041</td>\n",
       "      <td>一、金发科技拟与熊海涛女士签订《股份转让协议》，协议约定：以每股1.0509元的收购价格，收...</td>\n",
       "      <td>一、 ner_1 ner_1011_ 0_ 技拟与熊海涛女士签订《股份转让协议》，协议约定：...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           sentence  \\\n",
       "0   9259      2015年1月26日，多氟多化工股份有限公司与李云峰先生签署了《附条件生效的股份认购合同》   \n",
       "1   9136                      2、2016年2月5日，深圳市新纶科技股份有限公司与侯毅先   \n",
       "2    220  2015年10月26日，山东华鹏玻璃股份有限公司与张德华先生签署了附条件生效条件的《股份认购合同》   \n",
       "3   9041  2、2015年12月31日，印纪娱乐传媒股份有限公司与肖文革签订了《印纪娱乐传媒股份有限公司...   \n",
       "4  10041  一、金发科技拟与熊海涛女士签订《股份转让协议》，协议约定：以每股1.0509元的收购价格，收...   \n",
       "\n",
       "                                                 ner  \n",
       "0  2015年1月26日， ner_1002_ 司 ner_1003_ 云峰先生签署了《附条件生...  \n",
       "1             2、2016年2月5日， ner_1004_ 司与侯 ner_1005_ 先  \n",
       "2  2015年10月26日， ner_1006_ 司与 ner_1007_ 华先生签署了附条件生...  \n",
       "3  2、2015年12月31日， ner_1008_ 司与 ner_1009_ 革签订了《印纪娱...  \n",
       "4  一、 ner_1 ner_1011_ 0_ 技拟与熊海涛女士签订《股份转让协议》，协议约定：...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'氟化工': 1002,\n",
       "             '李云峰': 1003,\n",
       "             '深圳市新纶科技股份': 1004,\n",
       "             '侯毅': 1005,\n",
       "             '山东华鹏玻璃': 1006,\n",
       "             '张德华': 1007,\n",
       "             '印纪娱乐传媒': 1008,\n",
       "             '肖文革': 1009,\n",
       "             '金发科技': 1010,\n",
       "             '熊海涛': 1011,\n",
       "             '上海新朋实业': 1012,\n",
       "             '宋琳': 1013,\n",
       "             '王友林': 1014,\n",
       "             '康力电梯': 1015,\n",
       "             '彭聪': 1016,\n",
       "             '神州易桥100股权': 1017,\n",
       "             '百川能源': 1018,\n",
       "             '曹飞': 1019,\n",
       "             '珠海欧比特控制工程': 1020,\n",
       "             '颜军': 1021,\n",
       "             '成都云图': 1022,\n",
       "             '宋睿': 1023,\n",
       "             '上海岩石企业': 1024,\n",
       "             '柯塞威': 1025,\n",
       "             '广州阳普医疗科技股份': 1026,\n",
       "             '邓冠华': 1027,\n",
       "             '孙锋峰': 1028,\n",
       "             '金固': 1029,\n",
       "             '游族网络': 1030,\n",
       "             '林奇': 1031,\n",
       "             '厦门金达威集团股份': 1032,\n",
       "             '江斌': 1033,\n",
       "             '东方日升新能源': 1034,\n",
       "             '林海峰': 1035,\n",
       "             '神州数码集团股份': 1036,\n",
       "             '郭为': 1037,\n",
       "             '云科服务': 1038,\n",
       "             '浙江唐德影视': 1039,\n",
       "             '吴宏亮': 1040,\n",
       "             '广博': 1041,\n",
       "             '王利平': 1042,\n",
       "             '灵云传媒': 1043,\n",
       "             '金亚科技股份': 1044,\n",
       "             '金亚科技': 1045,\n",
       "             '周旭辉': 1046,\n",
       "             '成都天象互动科技': 1047,\n",
       "             '天象互动': 1048,\n",
       "             '汉鼎宇佑互联网': 1049,\n",
       "             '吴艳': 1050,\n",
       "             '深圳市方德智联投资管理': 1051,\n",
       "             '天津和达股权投资基金管理合伙企业': 1052,\n",
       "             '杭州雄健投资合伙企业': 1053,\n",
       "             '浙江奥鑫': 1054,\n",
       "             '杜应流': 1055,\n",
       "             '衡胜投资': 1056,\n",
       "             '崔根良': 1057,\n",
       "             '江苏亨通光电': 1058,\n",
       "             '江苏亚太轻合金科技股份': 1059,\n",
       "             '周福海': 1060,\n",
       "             '广东银禧科技股份': 1061,\n",
       "             '谭颂斌': 1062,\n",
       "             '山东日科化学': 1063,\n",
       "             '赵东日': 1064,\n",
       "             '广东塔牌集团股份': 1065,\n",
       "             '钟烈华': 1066,\n",
       "             '金浦钛业': 1067,\n",
       "             '郭金东': 1068,\n",
       "             '西水股份': 1069,\n",
       "             '南京熊猫电子': 1070,\n",
       "             '中国电子财务有限责任': 1071,\n",
       "             '腾达建设 ': 1072,\n",
       "             '腾达建设集团股份': 1073,\n",
       "             '上海申华风电新能源': 1074,\n",
       "             '东投能 源投资': 1075,\n",
       "             '中国银行': 1076,\n",
       "             '西安大雁塔支行': 1077,\n",
       "             '红豆集团': 1078,\n",
       "             ' 远东': 1079,\n",
       "             '深圳威新软件科技': 1080,\n",
       "             '金地商置': 1081,\n",
       "             '淮安广发银行分行': 1082,\n",
       "             '广发银行': 1083,\n",
       "             '锐电设计': 1084,\n",
       "             '锐电国 际贸易': 1085,\n",
       "             '泰格 林纸集团股份': 1086,\n",
       "             '泰格林纸': 1087,\n",
       "             '大唐国际发电': 1088,\n",
       "             '大唐塔山发电有限责任': 1089,\n",
       "             '广发证券': 1090,\n",
       "             '中航工业': 1091,\n",
       "             '中航资本': 1092,\n",
       "             '深圳市易尚展示': 1093,\n",
       "             '刘梦龙': 1094,\n",
       "             '国盛证券有限责任': 1095,\n",
       "             '北京市盈科律师': 1096,\n",
       "             '中国工商银行': 1097,\n",
       "             '沈阳和平支行': 1098,\n",
       "             '平安银行': 1099,\n",
       "             '广州中石化大厦支行': 1100,\n",
       "             '浙江南浔农村商业银行': 1101,\n",
       "             '孚支行': 1102,\n",
       "             '亿阳集团股份': 1103,\n",
       "             '亿阳信通': 1104,\n",
       "             '宁波维科精华集团股份': 1105,\n",
       "             '维科': 1106,\n",
       "             ' 誉德能源': 1107,\n",
       "             '柯罗尼': 1108,\n",
       "             '开封申华汽车博展': 1109,\n",
       "             '开封汽博园': 1110,\n",
       "             '沈金彦': 1111,\n",
       "             '中国信息信托投资公司': 1112,\n",
       "             '宁夏隆基': 1113,\n",
       "             '上海中国证券登记结算有限责任': 1114,\n",
       "             '深圳市梅江南投资': 1115,\n",
       "             '上海国际': 1116,\n",
       "             '上海实': 1117,\n",
       "             '天津 博苑高新材料': 1118,\n",
       "             '博苑公 司': 1119,\n",
       "             '中国电建 ': 1120,\n",
       "             '中国电力建设': 1121,\n",
       "             '辽宁时代万恒': 1122,\n",
       "             '王忠岩': 1123,\n",
       "             '杭州钱江四桥经营': 1124,\n",
       "             '钱江四桥': 1125,\n",
       "             '温州民商银行': 1126,\n",
       "             '牡丹江恒丰纸业': 1127,\n",
       "             '牡丹江恒丰纸业有限责任': 1128,\n",
       "             '四通 ': 1129,\n",
       "             '广东四通集团': 1130,\n",
       "             '五洲松德联合会计师': 1131,\n",
       "             '药业': 1132,\n",
       "             '康美保险': 1133,\n",
       "             '康美健康保险': 1134,\n",
       "             '广州珠江新城支行': 1135,\n",
       "             '天津港': 1136,\n",
       "             '天津金岸重工': 1137,\n",
       "             '用友网络': 1138,\n",
       "             '友网络科技股份': 1139,\n",
       "             '江苏澄星磷化工': 1140,\n",
       "             '澄星': 1141,\n",
       "             '东宝实业集团': 1142,\n",
       "             '李一奎 ': 1143,\n",
       "             '张园园': 1144,\n",
       "             '张燕青 ': 1145,\n",
       "             '浙江富润': 1146,\n",
       "             '浙江富润海茂纺织布艺': 1147,\n",
       "             '甘肃省农垦房地产开发': 1148,\n",
       "             '甘肃省农垦房 产开发': 1149,\n",
       "             '嘉兴宜租车 联网科技': 1150,\n",
       "             '嘉兴宜租车联网科技': 1151,\n",
       "             '方天山农业': 1152,\n",
       "             '天山农牧业': 1153,\n",
       "             '中远': 1154,\n",
       "             '国网重庆市电力公司': 1155,\n",
       "             '重庆电力': 1156,\n",
       "             '马鞍山山鹰纸业': 1157,\n",
       "             '吴丽萍': 1158,\n",
       "             '北药': 1159,\n",
       "             ' 中国华润': 1160,\n",
       "             '五 ': 1161,\n",
       "             '蒋衡杰': 1162,\n",
       "             '通策医疗': 1163,\n",
       "             ' 通策医疗投资': 1164,\n",
       "             '安通物流': 1165,\n",
       "             '安盛船务': 1166,\n",
       "             '天安财险': 1167,\n",
       "             '江西赣南海欣药业': 1168,\n",
       "             '陈谋亮': 1169,\n",
       "             '杭州上海浦东发展银行分行': 1170,\n",
       "             '上海浦东发展银行利多': 1171,\n",
       "             '许望生': 1172,\n",
       "             '百联': 1173,\n",
       "             '东方商厦': 1174,\n",
       "             '南山铝业': 1175,\n",
       "             '南山': 1176,\n",
       "             '深圳能源集团股份': 1177,\n",
       "             '国泰君安': 1178,\n",
       "             '申能': 1179,\n",
       "             '中天合创能源有限责任': 1180,\n",
       "             '杭州海骏科技': 1181,\n",
       "             '吕建明': 1182,\n",
       "             '南通科技 ': 1183,\n",
       "             '南通科技投资集团股份': 1184,\n",
       "             '美尚生态景观': 1185,\n",
       "             '秦文英': 1186,\n",
       "             '大晟时代文化投资': 1187,\n",
       "             '周镇科': 1188,\n",
       "             '上海申达投资 ': 1189,\n",
       "             '上海银行浦东 分行': 1190,\n",
       "             '兴民智通': 1191,\n",
       "             '王志成': 1192,\n",
       "             '维力医疗 ': 1193,\n",
       "             '广州维力医疗器械': 1194,\n",
       "             '易乘投资': 1195,\n",
       "             '张振新': 1196,\n",
       "             '青鸟华光': 1197,\n",
       "             '东方国兴': 1198,\n",
       "             '深圳市中恒泰': 1199,\n",
       "             '陈少鞍': 1200,\n",
       "             '新潮实业 ': 1201,\n",
       "             '烟台新潮实业': 1202,\n",
       "             '西 水': 1203,\n",
       "             '华夏绿色': 1204,\n",
       "             '深圳基金企业': 1205,\n",
       "             '阳泉煤业有限责任': 1206,\n",
       "             '天泰': 1207,\n",
       "             '浙江金鹰': 1208,\n",
       "             '金鹰': 1209,\n",
       "             '红豆网络 ': 1210,\n",
       "             '红 豆网络': 1211,\n",
       "             '上海奥柏内燃机配件': 1212,\n",
       "             '上海崇明奥琰内燃机配件': 1213,\n",
       "             '崇明房地产开发': 1214,\n",
       "             '上海亚通': 1215,\n",
       "             '金桥 B 股 ': 1216,\n",
       "             '上海金桥出口加工区开发': 1217,\n",
       "             '甘肃天润薯业有限责任': 1218,\n",
       "             '甘肃农业科技': 1219,\n",
       "             '永鼎': 1220,\n",
       "             '沱牌舍得 ': 1221,\n",
       "             '四川沱牌舍得酒业': 1222,\n",
       "             '天堂硅谷': 1223,\n",
       "             '天堂硅谷 ': 1224,\n",
       "             '凯乐科技': 1225,\n",
       "             '湖北凯乐科技股份': 1226,\n",
       "             '甘肃省农垦有限责任': 1227,\n",
       "             '瑞华会计师': 1228,\n",
       "             '': 1229,\n",
       "             '天 安财险': 1230,\n",
       "             '苏州天房投资': 1231,\n",
       "             '杨杰': 1232,\n",
       "             '北京空港科技园区': 1233,\n",
       "             '北京天源建筑工程有限责任': 1234,\n",
       "             '张德华 ': 1235,\n",
       "             '江苏保千里视像科技集团股份': 1236,\n",
       "             '庄敏': 1237,\n",
       "             '中国建设银行上海市分行': 1238,\n",
       "             '滁州天星': 1239,\n",
       "             '合肥天星': 1240,\n",
       "             '贵州盘江煤层气开发利用有限责任': 1241,\n",
       "             '杨世梁': 1242,\n",
       "             '中远集运': 1243,\n",
       "             '中散': 1244,\n",
       "             '刘觯段': 1245,\n",
       "             '东方钢铁电子商务': 1246,\n",
       "             '宝钢股份': 1247,\n",
       "             '阿波罗': 1248,\n",
       "             '秋林': 1249,\n",
       "             '1海奥柏内燃机配件': 1250,\n",
       "             '桐昆': 1251,\n",
       "             '桐昆集团股份 限': 1252,\n",
       "             '郴州市城 市建设投资': 1253,\n",
       "             '湖南省分行': 1254,\n",
       "             '深圳金信诺高新技术': 1255,\n",
       "             '黄昌华': 1256,\n",
       "             '深圳兴飞睿德电子 ': 1257,\n",
       "             '睿德电子': 1258,\n",
       "             '文山电力 ': 1259,\n",
       "             '云南文山电力': 1260,\n",
       "             '宋城演艺': 1261,\n",
       "             '宁波宋城七弦投资管理': 1262,\n",
       "             '李汉华': 1263,\n",
       "             '蔡鉴蔡': 1264,\n",
       "             '江苏三明新能源': 1265,\n",
       "             '三明宿迁新能源浦发银行分行': 1266,\n",
       "             '中国农业银行': 1267,\n",
       "             '益阳中国农业银行分行': 1268,\n",
       "             '李维董': 1269,\n",
       "             '萍脊镜姆ǘ': 1270,\n",
       "             '海泰': 1271,\n",
       "             '伊力特糖业': 1272,\n",
       "             '康欣新材': 1273,\n",
       "             '康欣新材 ': 1274,\n",
       "             '山东凯马汽车制造': 1275,\n",
       "             '凯马汽 车': 1276,\n",
       "             '天津振港通信工程': 1277,\n",
       "             '重庆博腾制药科技股份': 1278,\n",
       "             '重庆润生科技': 1279,\n",
       "             '宁夏隆基硅材料': 1280,\n",
       "             '李振国': 1281,\n",
       "             '北海国发海洋生物产业': 1282,\n",
       "             '中国建设银行': 1283,\n",
       "             '美好置业集团股份': 1284,\n",
       "             '刘道明': 1285,\n",
       "             '西水 ': 1286,\n",
       "             '德润租赁': 1287,\n",
       "             '德信担保': 1288,\n",
       "             '明匠智能': 1289,\n",
       "             '上海农场': 1290,\n",
       "             '川东农场': 1291,\n",
       "             '天津松江': 1292,\n",
       "             '松江': 1293,\n",
       "             '中航复材': 1294,\n",
       "             '优材京航': 1295,\n",
       "             '浙江水晶光电科技股份': 1296,\n",
       "             '台州星星置业': 1297,\n",
       "             '长江证券': 1298,\n",
       "             '长江财富': 1299,\n",
       "             '徐潮': 1300,\n",
       "             '孙伟': 1301,\n",
       "             '张洪': 1302,\n",
       "             '鹏翎': 1303,\n",
       "             '常州亿晶光电科技': 1304,\n",
       "             '齐普 生': 1305,\n",
       "             '齐普生': 1306,\n",
       "             '江苏法尔胜精细钢绳': 1307,\n",
       "             '江苏法尔胜': 1308,\n",
       "             '中晶': 1309,\n",
       "             '上海实业': 1310,\n",
       "             '上海投资产经营': 1311,\n",
       "             '上海中建信置业': 1312,\n",
       "             '长江精工钢结构': 1313,\n",
       "             '阳泉煤业': 1314,\n",
       "             '安徽全柴天机械': 1315,\n",
       "             '天机械': 1316,\n",
       "             '亚星客车 ': 1317,\n",
       "             '扬州亚星客车': 1318,\n",
       "             '兰州惠仁 ': 1319,\n",
       "             '南京医药': 1320,\n",
       "             '陶昀': 1321,\n",
       "             '天伟化工': 1322,\n",
       "             '天业': 1323,\n",
       "             '河南黄河旋风': 1324,\n",
       "             '顾清': 1325,\n",
       "             '上海远望谷信息技术': 1326,\n",
       "             '白英': 1327,\n",
       "             '张福喜': 1328,\n",
       "             '长江电力': 1329,\n",
       "             '广州集团股份': 1330,\n",
       "             '中华人民共和国': 1331,\n",
       "             '天津运河城投资': 1332,\n",
       "             '大庆刘': 1333,\n",
       "             '国核浙核能': 1334,\n",
       "             '海能达通信': 1335,\n",
       "             '陈清州': 1336,\n",
       "             '秋 林': 1337,\n",
       "             '深圳市远望谷信息技术': 1338,\n",
       "             '上海汽车工业': 1339,\n",
       "             '长江养老保险股 份': 1340,\n",
       "             '北京富贵花开投资管理': 1341,\n",
       "             '金洲管道': 1342,\n",
       "             '成都天翔环境': 1343,\n",
       "             '杭州欧盛腾水技术': 1344,\n",
       "             '华远地产': 1345,\n",
       "             '山东矿机集团股份': 1346,\n",
       "             '赵华涛': 1347,\n",
       "             '福建纳川管材科技股份': 1348,\n",
       "             '陈志江': 1349,\n",
       "             '中国电建华东勘测设计研究院公 司': 1350,\n",
       "             '桐乡市临杭经济区新市镇开发建设': 1351,\n",
       "             '吉祥创赢': 1352,\n",
       "             '吉发 智盈': 1353,\n",
       "             '黄金': 1354,\n",
       "             '北京福田戴姆勒汽车': 1355,\n",
       "             '沧州 大化 ': 1356,\n",
       "             '沧州 大化': 1357,\n",
       "             '德稻资产': 1358,\n",
       "             '北京银杏树信息技术服务 ': 1359,\n",
       "             '上海皓石资产管理': 1360,\n",
       "             '马平': 1361,\n",
       "             '罗顿发': 1362,\n",
       "             ' 罗顿': 1363,\n",
       "             '浙江物产 ': 1364,\n",
       "             '物产 ': 1365,\n",
       "             '天津磁卡 ': 1366,\n",
       "             '天津环球磁卡': 1367,\n",
       "             '华北电力科学院有限责任': 1368,\n",
       "             '联明': 1369,\n",
       "             '上海联明机械': 1370,\n",
       "             '江地产': 1371,\n",
       "             '江西江中物业有限责任': 1372,\n",
       "             '兰州惠仁': 1373,\n",
       "             '安徽山鹰纸业': 1374,\n",
       "             '安徽山 鹰纸业': 1375,\n",
       "             '廊坊银行': 1376,\n",
       "             '黄茂如': 1377,\n",
       "             '中兆投资管理': 1378,\n",
       "             '宁波建乐建筑装潢': 1379,\n",
       "             '浙江置华建设': 1380,\n",
       "             '河南黄河旋风股': 1381,\n",
       "             '陈俊': 1382,\n",
       "             '申华东投新能源投资': 1383,\n",
       "             '申华东投': 1384,\n",
       "             '内蒙古伊利实业集团': 1385,\n",
       "             '黑龙江伊利乳业有限责任': 1386,\n",
       "             '新华联文化旅游': 1387,\n",
       "             '新华联': 1388,\n",
       "             '深圳威新 ': 1389,\n",
       "             '深圳威': 1390,\n",
       "             '深圳市赢时胜信息技术': 1391,\n",
       "             '唐球': 1392,\n",
       "             '上海大湖优势投资管理中心': 1393,\n",
       "             '福州百 洋海味食品': 1394,\n",
       "             '中航 复材': 1395,\n",
       "             '飞乐': 1396,\n",
       "             '仪电电子': 1397,\n",
       "             '太极计算机': 1398,\n",
       "             '中国电子科技海洋信息技术研究院': 1399,\n",
       "             '苏州市苏地 ': 1400,\n",
       "             '唐山中润': 1401,\n",
       "             '开滦财务': 1402,\n",
       "             '南方汇通': 1403,\n",
       "             '蔡志奇': 1404,\n",
       "             '广州交通银行 白云支行': 1405,\n",
       "             '蕴通财富': 1406,\n",
       "             '渤海轮渡': 1407,\n",
       "             '黄海造船': 1408,\n",
       "             '桐昆控 ': 1409,\n",
       "             '桐昆集团股份': 1410,\n",
       "             '苏州新区高新技术产业': 1411,\n",
       "             '苏州高新创业投资': 1412,\n",
       "             '安智勇': 1413,\n",
       "             '优材京航部': 1414,\n",
       "             '优材京航 ': 1415,\n",
       "             '上海德稻集群文化创意产业': 1416,\n",
       "             '李维': 1417,\n",
       "             '方大炭素新材料 科技股份': 1418,\n",
       "             '方大锦化化工科技股份': 1419,\n",
       "             '杭州凤侠': 1420,\n",
       "             '凤凰数媒': 1421,\n",
       "             '农业银行': 1422,\n",
       "             '汇利丰': 1423,\n",
       "             '陕西神渭管道运输有限责任': 1424,\n",
       "             '西安咸宁中国银行路支行': 1425,\n",
       "             '方佑昌灯光器材': 1426,\n",
       "             '佛山电器照明': 1427,\n",
       "             '浙江东日': 1428,\n",
       "             '格林美': 1429,\n",
       "             '陈星题': 1430,\n",
       "             '东海证券': 1431,\n",
       "             '天': 1432,\n",
       "             '深圳兴飞': 1433,\n",
       "             '岳阳林纸': 1434,\n",
       "             '恒泰房地产': 1435,\n",
       "             '建信 资本管理有限责任': 1436,\n",
       "             '建信资本': 1437,\n",
       "             '崇明奥琰': 1438,\n",
       "             '杭州中恒电气': 1439,\n",
       "             '朱国锭': 1440,\n",
       "             '台州刚泰黄金饰品': 1441,\n",
       "             '赵瑞俊': 1442,\n",
       "             '唐山中润煤化工': 1443,\n",
       "             '徐贺明': 1444,\n",
       "             '宁武榆 树坡煤业': 1445,\n",
       "             '华润赛科': 1446,\n",
       "             '大西洋 ': 1447,\n",
       "             '四川大西洋焊接材料': 1448,\n",
       "             '雅戈尔 ': 1449,\n",
       "             '雅戈尔集团': 1450,\n",
       "             '上海大西洋焊接材料有限责任': 1451,\n",
       "             '李欣雨': 1452,\n",
       "             '王进飞': 1453,\n",
       "             '南京奥特佳': 1454,\n",
       "             '李洁': 1455,\n",
       "             '远东': 1456,\n",
       "             ' 秋林': 1457,\n",
       "             '杭州汇智间': 1458,\n",
       "             '盘江': 1459,\n",
       "             '吉林敖东药业集团股份': 1460,\n",
       "             '哈尔滨秋林集团股份': 1461,\n",
       "             '华林证券': 1462,\n",
       "             '上海锐珩投资管理 ': 1463,\n",
       "             '上海锐翎投资管理': 1464,\n",
       "             '哈尔滨天津银行西青支行': 1465,\n",
       "             '伊利': 1466,\n",
       "             '张忠': 1467,\n",
       "             '杨川': 1468,\n",
       "             '孟寰': 1469,\n",
       "             '上海东浩环保装备': 1470,\n",
       "             '东浩': 1471,\n",
       "             '株洲湖南华升雪松': 1472,\n",
       "             '株洲市金爽资产有限责任': 1473,\n",
       "             '绵世方达': 1474,\n",
       "             '德新 景': 1475,\n",
       "             '浙江星星科技股份': 1476,\n",
       "             '叶仙玉': 1477,\n",
       "             '涪陵区重庆市峡星电力勘察设计': 1478,\n",
       "             '峡星': 1479,\n",
       "             '中远集装箱运输': 1480,\n",
       "             '中远散货运输': 1481,\n",
       "             '河南羚锐制药': 1482,\n",
       "             '陈燕': 1483,\n",
       "             '双鹿实业': 1484,\n",
       "             '陈士良 ': 1485,\n",
       "             '上海申达股 份': 1486,\n",
       "             '上海申达': 1487,\n",
       "             '德勤华永会计师': 1488,\n",
       "             '上汽': 1489,\n",
       "             '申华': 1490,\n",
       "             '上海申华': 1491,\n",
       "             '民盛金科': 1492,\n",
       "             '浙江泰晟新材料科技': 1493,\n",
       "             '维格娜丝 ': 1494,\n",
       "             ' 维格娜丝时装': 1495,\n",
       "             '深圳市尚荣医疗': 1496,\n",
       "             '梁桂秋': 1497,\n",
       "             '广东明珠集团股份': 1498,\n",
       "             '广东润房地产投资': 1499,\n",
       "             '新疆银龙': 1500,\n",
       "             '银龙': 1501,\n",
       "             '湖北康欣新材料科技有限责任': 1502,\n",
       "             '贵州黎阳装备科技': 1503,\n",
       "             '黎阳装备': 1504,\n",
       "             '云图科技': 1505,\n",
       "             '邢舫': 1506,\n",
       "             '杭州浙银汇智资本管理公 司': 1507,\n",
       "             '贵州 盘江煤层气开发利用有限责任': 1508,\n",
       "             '浙江义乌购电子商务': 1509,\n",
       "             '浙江稠 州商业银行': 1510,\n",
       "             '浙江开尔新材料': 1511,\n",
       "             '邢翰学': 1512,\n",
       "             '双钱': 1513,\n",
       "             '上海轮胎': 1514,\n",
       "             '安徽 区域': 1515,\n",
       "             '上海飞乐音响': 1516,\n",
       "             '北京华联商厦': 1517,\n",
       "             '武汉海融': 1518,\n",
       "             '财务': 1519,\n",
       "             '陈虹': 1520,\n",
       "             '上海国际投资': 1521,\n",
       "             '上海 国际': 1522,\n",
       "             '上海大众企业管理': 1523,\n",
       "             '大众交通': 1524,\n",
       "             '安盛': 1525,\n",
       "             '榆树坡': 1526,\n",
       "             '天然': 1527,\n",
       "             '湖北福星科技股份': 1528,\n",
       "             '福星': 1529,\n",
       "             '徐涛明': 1530,\n",
       "             '吉蔚娣': 1531,\n",
       "             '郑州煤矿机械集团股份Zhengzhou Coal Mining Machinery Group ': 1532,\n",
       "             '中铭国际': 1533,\n",
       "             '钟化': 1534,\n",
       "             '博立信支付': 1535,\n",
       "             '上海北特科技股份': 1536,\n",
       "             '靳晓堂': 1537,\n",
       "             '竞缘咀什 ': 1538,\n",
       "             '同煤': 1539,\n",
       "             '山西漳泽电力': 1540,\n",
       "             '宏昌电子 ': 1541,\n",
       "             '宏昌电子材料': 1542,\n",
       "             '鼎力租赁': 1543,\n",
       "             '天津博苑高新材料': 1544,\n",
       "             '李春刚': 1545,\n",
       "             '江苏亚邦染料': 1546,\n",
       "             '连云港亚邦龙涛置业': 1547,\n",
       "             '中航高科': 1548,\n",
       "             '绍兴上虞口腔医院': 1549,\n",
       "             '王仁飞': 1550,\n",
       "             '鼎欣房产': 1551,\n",
       "             '山东黄金矿业': 1552,\n",
       "             '山东黄金': 1553,\n",
       "             '天科技': 1554,\n",
       "             '江东金具': 1555,\n",
       "             '浙江济民制药': 1556,\n",
       "             '李慧慧 ': 1557,\n",
       "             '蓝星新材': 1558,\n",
       "             '上海中国证券登记结算有限责任分 ': 1559,\n",
       "             '诸暨富润染整': 1560,\n",
       "             '陈喜彬': 1561,\n",
       "             '上投': 1562,\n",
       "             '华斯': 1563,\n",
       "             '贺国英': 1564,\n",
       "             '万家文化 ': 1565,\n",
       "             '浙江万好万家文化': 1566,\n",
       "             '四川路桥 ': 1567,\n",
       "             '铁能电力公司': 1568,\n",
       "             '精铸': 1569,\n",
       "             '中航租赁': 1570,\n",
       "             '山东 黄金': 1571,\n",
       "             '国家核电技术': 1572,\n",
       "             ' 浙电力': 1573,\n",
       "             '长江通信 ': 1574,\n",
       "             '武汉长江通信产业集团股份': 1575,\n",
       "             '南通耀荣玻璃股份有限 ': 1576,\n",
       "             '南通耀荣玻璃': 1577,\n",
       "             '交通银行': 1578,\n",
       "             '浙报数字文化集团股份': 1579,\n",
       "             '浙报': 1580,\n",
       "             '广西柳州医药': 1581,\n",
       "             '柳州医药': 1582,\n",
       "             '浙江康恩贝制药': 1583,\n",
       "             '朱麟': 1584,\n",
       "             '烟台大地房地产开发': 1585,\n",
       "             '申达': 1586,\n",
       "             '上海东洲资产评估': 1587,\n",
       "             '浙江东日 ': 1588,\n",
       "             ' 现代集团': 1589,\n",
       "             '赵笃学': 1590,\n",
       "             '王甫': 1591,\n",
       "             '唐山航岛海洋重工': 1592,\n",
       "             '袁晓纪住 ': 1593,\n",
       "             '黑化': 1594,\n",
       "             '长城国融': 1595,\n",
       "             '河北衡水老白干酒业': 1596,\n",
       "             '河北冀衡化学': 1597,\n",
       "             '福建省福能龙安热电': 1598,\n",
       "             '黄友星5': 1599,\n",
       "             '内蒙古神舟硅业有限责任': 1600,\n",
       "             '张耀平': 1601,\n",
       "             '美康生物科技股份': 1602,\n",
       "             '邹炳德': 1603,\n",
       "             '红豆': 1604,\n",
       "             '江苏红豆实业': 1605,\n",
       "             '北京正行通资产评估': 1606,\n",
       "             '中国诚通': 1607,\n",
       "             '郑州光大银行纬二路 支行': 1608,\n",
       "             '光大银行': 1609,\n",
       "             '老百姓药房连锁': 1610,\n",
       "             '湖南老百姓医药投资管理': 1611,\n",
       "             '罗泾电厂': 1612,\n",
       "             '中国电建西北勘测设计研究院 限': 1613,\n",
       "             '西北格尔木': 1614,\n",
       "             '南京栖霞建设': 1615,\n",
       "             '刘健君': 1616,\n",
       "             '安徽中威光电材料': 1617,\n",
       "             '华能国际电力': 1618,\n",
       "             '湖北华能应城热电有限责任': 1619,\n",
       "             '江苏阳光云亭热电': 1620,\n",
       "             '江阴云亭热力': 1621,\n",
       "             '河南安智勇实业集团': 1622,\n",
       "             '尤志安': 1623,\n",
       "             '亚盛': 1624,\n",
       "             '甘肃亚盛实业': 1625,\n",
       "             '交通银行 内蒙古自治区分行': 1626,\n",
       "             '扬州阿波罗蓄电池': 1627,\n",
       "             '中国光大银行 ': 1628,\n",
       "             '沈阳五爱支行': 1629,\n",
       "             '北京工业投资管理': 1630,\n",
       "             '石幼文': 1631,\n",
       "             '安徽众志会计师': 1632,\n",
       "             '山鹰': 1633,\n",
       "             '浙江物产元通集团股份': 1634,\n",
       "             '浙江省物产': 1635,\n",
       "             '深圳兴飞所': 1636,\n",
       "             '北京长翔新能源投资': 1637,\n",
       "             '王迅': 1638,\n",
       "             '浙商保险': 1639,\n",
       "             '南京康尼精密机械': 1640,\n",
       "             '高文明': 1641,\n",
       "             '德新景': 1642,\n",
       "             '天津松江 ': 1643,\n",
       "             '湖南天润数字娱乐文化传媒': 1644,\n",
       "             '广东恒润互兴资产管理': 1645})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dict_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 850/850 [01:32<00:00,  9.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# deal with training data\n",
    "train_data = pd.read_csv('../data/info_extract/train_data.csv', encoding = 'gb2312', header=0)\n",
    "train_data['ner'] = None\n",
    "\n",
    "for i in trange(len(train_data)):\n",
    "    # if the sentence is not labelled, recognize the named entity and replaced with ner_index\n",
    "    if train_data.iloc[i, :]['member1'] == '0' and train_data.iloc[i, :]['member2'] == '0':\n",
    "        sentence = copy(train_data.iloc[i, 1])\n",
    "        words, ners = fool.analysis(sentence)\n",
    "        ners[0].sort(key=lambda x: x[0], reverse=True)\n",
    "        for start, end, ner_type, ner_name in ners[0]:\n",
    "            if ner_type == 'company' or ner_type == 'person':\n",
    "                company_main_name = main_extract(ner_name, stop_word, d_4_delete, d_city_province)\n",
    "\n",
    "                if company_main_name not in ner_dict_new:\n",
    "                    ner_id += 1\n",
    "                    ner_dict_new[company_main_name] = ner_id\n",
    "\n",
    "                sentence = sentence[:start] + ' ner_' + str(ner_dict_new[company_main_name]) + '_ ' + sentence[end - 1:]\n",
    "        train_data.iloc[i, -1] = sentence\n",
    "    else:\n",
    "        # for labelled sentence , replace the entity with ner_index\n",
    "        sentence = copy(train_data.iloc[i, :]['sentence'])\n",
    "        for company_main_name in [train_data.iloc[i, :]['member1'], train_data.iloc[i, :]['member2']]:\n",
    "\n",
    "            company_main_name_new = main_extract(company_main_name, stop_word, d_4_delete, d_city_province)\n",
    "\n",
    "            if company_main_name_new not in ner_dict_new:\n",
    "                ner_id += 1\n",
    "                ner_dict_new[company_main_name_new] = ner_id\n",
    "\n",
    "            sentence = re.sub(company_main_name, ' ner_%s_ ' % (str(ner_dict_new[company_main_name_new])), sentence)\n",
    "        train_data.iloc[i, -1] = sentence\n",
    "\n",
    "ner_dict_reverse_new = {id:name for name, id in ner_dict_new.items()}\n",
    "        \n",
    "y = train_data.loc[:, ['tag']]\n",
    "train_num = len(train_data)\n",
    "X_train = train_data[['ner']]\n",
    "\n",
    "X = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "      <th>member1</th>\n",
       "      <th>member2</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6461</td>\n",
       "      <td>与本公司关系:受同一公司控制 2，杭州富生电器有限公司企业类型: 有限公司注册地址: 富阳市...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>与本公司关系:受同一公司控制 2， ner_1647_ 司企业类型: 有限公司注册地址: 富...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2111</td>\n",
       "      <td>三、关联交易标的基本情况 1、交易标的基本情况 公司名称:红豆集团财务有限公司 公司地址:无...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>三、关联交易标的基本情况 1、交易标的基本情况 公司名称: ner_1649_ 司地址:无锡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9603</td>\n",
       "      <td>2016年协鑫集成科技股份有限公司向瑞峰（张家港）光伏科技有限公司支付设备款人民币4，515...</td>\n",
       "      <td>1</td>\n",
       "      <td>协鑫集成科技股份有限公司</td>\n",
       "      <td>瑞峰（张家港）光伏科技有限公司</td>\n",
       "      <td>2016年 ner_1650_ 向 ner_1651_ 支付设备款人民币4，515，770.00元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3456</td>\n",
       "      <td>证券代码:600777 证券简称:新潮实业 公告编号:2015-091 烟台新潮实业股份有限...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>证券代码:600777 证券简称: ner_1201_  公告编号:2015-091  ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8844</td>\n",
       "      <td>本集团及广发证券股份有限公司持有辽宁成大股份有限公司股票的本期变动系买卖一揽子沪深300指数...</td>\n",
       "      <td>1</td>\n",
       "      <td>广发证券股份有限公司</td>\n",
       "      <td>辽宁成大股份有限公司</td>\n",
       "      <td>本集团及 ner_1090_ 持有 ner_1652_ 股票的本期变动系买卖一揽子沪深300...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           sentence  tag       member1  \\\n",
       "0  6461  与本公司关系:受同一公司控制 2，杭州富生电器有限公司企业类型: 有限公司注册地址: 富阳市...    0             0   \n",
       "1  2111  三、关联交易标的基本情况 1、交易标的基本情况 公司名称:红豆集团财务有限公司 公司地址:无...    0             0   \n",
       "2  9603  2016年协鑫集成科技股份有限公司向瑞峰（张家港）光伏科技有限公司支付设备款人民币4，515...    1  协鑫集成科技股份有限公司   \n",
       "3  3456  证券代码:600777 证券简称:新潮实业 公告编号:2015-091 烟台新潮实业股份有限...    0             0   \n",
       "4  8844  本集团及广发证券股份有限公司持有辽宁成大股份有限公司股票的本期变动系买卖一揽子沪深300指数...    1    广发证券股份有限公司   \n",
       "\n",
       "           member2                                                ner  \n",
       "0                0  与本公司关系:受同一公司控制 2， ner_1647_ 司企业类型: 有限公司注册地址: 富...  \n",
       "1                0  三、关联交易标的基本情况 1、交易标的基本情况 公司名称: ner_1649_ 司地址:无锡...  \n",
       "2  瑞峰（张家港）光伏科技有限公司  2016年 ner_1650_ 向 ner_1651_ 支付设备款人民币4，515，770.00元  \n",
       "3                0  证券代码:600777 证券简称: ner_1201_  公告编号:2015-091  ne...  \n",
       "4       辽宁成大股份有限公司  本集团及 ner_1090_ 持有 ner_1652_ 股票的本期变动系买卖一揽子沪深300...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>与本公司关系:受同一公司控制 2， ner_1647_ 司企业类型: 有限公司注册地址: 富...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>三、关联交易标的基本情况 1、交易标的基本情况 公司名称: ner_1649_ 司地址:无锡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016年 ner_1650_ 向 ner_1651_ 支付设备款人民币4，515，770.00元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>证券代码:600777 证券简称: ner_1201_  公告编号:2015-091  ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>本集团及 ner_1090_ 持有 ner_1652_ 股票的本期变动系买卖一揽子沪深300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>近日，该子公司已完成工商注册登记手续，并领取了南京市工商行政管理局颁发的&lt;企业法人营业执照&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>(二)本次交易构成关联交易正元投资拟认购金额不低于 13 亿元且不低于本次配套融资总额的 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>证券代码:600225 证券简称: ner_1643_  公告编号:临 20 ner_129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2015年3月31日， ner_1644_ 司与广东恒润互兴 ner_1645_ 件生效的《...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>三、本公司不会利用对 ner_1069_ ner_1069_ 制关系损害西水股份及其他股东 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1269 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ner\n",
       "0    与本公司关系:受同一公司控制 2， ner_1647_ 司企业类型: 有限公司注册地址: 富...\n",
       "1    三、关联交易标的基本情况 1、交易标的基本情况 公司名称: ner_1649_ 司地址:无锡...\n",
       "2    2016年 ner_1650_ 向 ner_1651_ 支付设备款人民币4，515，770.00元\n",
       "3    证券代码:600777 证券简称: ner_1201_  公告编号:2015-091  ne...\n",
       "4    本集团及 ner_1090_ 持有 ner_1652_ 股票的本期变动系买卖一揽子沪深300...\n",
       "..                                                 ...\n",
       "414  近日，该子公司已完成工商注册登记手续，并领取了南京市工商行政管理局颁发的<企业法人营业执照>...\n",
       "415  (二)本次交易构成关联交易正元投资拟认购金额不低于 13 亿元且不低于本次配套融资总额的 2...\n",
       "416  证券代码:600225 证券简称: ner_1643_  公告编号:临 20 ner_129...\n",
       "417  2015年3月31日， ner_1644_ 司与广东恒润互兴 ner_1645_ 件生效的《...\n",
       "418  三、本公司不会利用对 ner_1069_ ner_1069_ 制关系损害西水股份及其他股东 ...\n",
       "\n",
       "[1269 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Relation Extraction\n",
    "\n",
    "After the NER part, we need to build a graph database to store the dug relationships. Based on our data, the relationship describes the equity transactions between two entities. We could use the undirectional edge to depict this kind of relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "firstly, remove the stop words and change them to the tf-idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pyltp import Segmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer dict\n",
    "with open('../data/user_dict.txt', 'w', encoding='utf-8') as fw:\n",
    "    for v in ['一', '二', '三', '四', '五', '六', '七', '八', '九', '十']:\n",
    "        fw.write( v + '号企业 ni\\n')\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1269, 3897)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "LTP_DATA_DIR = './ltp_data_v3.4/ltp_data_v3.4.0'\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')\n",
    "segmentor = Segmentor(cws_model_path, lexicon_path = '../data/user_dict.txt')  \n",
    "\n",
    "fr = open(r'../data/dict/stopwords.txt', encoding='utf-8')   \n",
    "stop_word = fr.readlines()\n",
    "stop_word = [re.sub(r'(\\r|\\n)*','',stop_word[i]) for i in range(len(stop_word))]\n",
    "\n",
    "\"\"\"\n",
    "build rules to filter the ner column\n",
    "1. remove stop words\n",
    "2. remove entity\n",
    "3. remove special marks and numbers\n",
    "\"\"\"\n",
    "f1 = lambda x: re.sub(r'ner\\_\\d\\d\\d\\d\\_','',x)\n",
    "f2 = lambda x: re.compile(\"[^\\u4e00-\\u9fa5]\").sub('', x)\n",
    "# remain chinese characters, numbers, letters  \n",
    "f3 = lambda x: ' '.join([word for word in segmentor.segment(x) if word not in stop_word])\n",
    "f4 = lambda x: re.compile(\"[^\\u4e00-\\u9fa5^a-z^A-Z^0-9]\").sub('', x)\n",
    "\n",
    "corpus=X['ner'].map(f1).map(f2).map(f3).tolist()\n",
    "\n",
    "corpus_parse=X['ner'].map(f4).tolist()\n",
    "segmentor.release()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()  \n",
    "X_tfidf = vectorizer.fit_transform(corpus).toarray() \n",
    "print(X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we retrive the syntactic features\n",
    "1. absolute distance between entities\n",
    "2. syntactic distance between entities\n",
    "3. distance between key words and entities\n",
    "4. dependency syntactic relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyltp import Parser\n",
    "from pyltp import Segmentor\n",
    "from pyltp import Postagger\n",
    "import networkx as nx\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Digraph\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LTP_DATA_DIR = './ltp_data_v3.4/ltp_data_v3.4.0'\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')\n",
    "segmentor = Segmentor(cws_model_path, lexicon_path = '../data/user_dict.txt') \n",
    "\n",
    "pos_model_path = os.path.join(LTP_DATA_DIR, 'pos.model')\n",
    "postagger = Postagger(pos_model_path)\n",
    "\n",
    "parse_model_path = os.path.join(LTP_DATA_DIR, 'parser.model')\n",
    "parser = Parser(parse_model_path)\n",
    "\n",
    "\n",
    "SEN_TAGS = [\"SBV\",\"VOB\",\"IOB\",\"FOB\",\"DBL\",\"ATT\",\"ADV\",\"CMP\",\"COO\",\"POB\",\"LAD\",\"RAD\",\"IS\",\"HED\"]\n",
    "key_words = [\"收购\", \"竞拍\", \"转让\", \"扩张\", \"并购\", \"注资\", \"整合\", \"并入\", \"竞购\", \"竞买\", \"支付\", \"收购价\", \"收购价格\", \"承购\", \"购得\", \"购进\",\n",
    "             \"购入\", \"买进\", \"买入\", \"赎买\", \"购销\", \"议购\", \"函购\", \"函售\", \"抛售\", \"售卖\", \"销售\", \"转售\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(arcs_ret, words, source, target, isGraph = False):\n",
    "    \"\"\"\n",
    "    calculate the shorest dependency parsing distance\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    # add node\n",
    "    for i in list(arcs_ret.index):\n",
    "        G.add_node(i)\n",
    "    \n",
    "    #add edge\n",
    "    for i in range(len(arcs_ret)):\n",
    "        head = arcs_ret.iloc[i, -2]\n",
    "        index = i + 1\n",
    "        G.add_edge(index, head)\n",
    "\n",
    "    if isGraph:\n",
    "        nx.draw(G, with_labels=True)\n",
    "        plt.savefig(\"undirected_graph_2.png\")\n",
    "        plt.close()\n",
    "\n",
    "    try:\n",
    "        source_index = words.index(source) + 1 \n",
    "        target_index = words.index(target) + 1 \n",
    "        distance = nx.shortest_path_length(G, source=source_index, target=target_index)\n",
    "        return distance\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_entity_modification(s):\n",
    "    \"\"\"\n",
    "    original entity name is ner_1003_ \n",
    "    we need to change it to another name to help tagging and parsing\n",
    "    \"\"\"\n",
    "    tmp_ner_dict = defaultdict(lambda:\"\")\n",
    "    num_lst = ['一', '二', '三', '四', '五', '六', '七', '八', '九', '十']\n",
    "\n",
    "\n",
    "    # 将公司代码替换为特殊称谓，保证分词词性正确\n",
    "    for i, ner in enumerate(list(set(re.findall(r'(ner\\d\\d\\d\\d)', s)))):\n",
    "        try:\n",
    "            tmp_ner_dict[num_lst[i] + '号企业'] = ner\n",
    "        except IndexError:\n",
    "            # TODO：定义错误情况的输出\n",
    "            # TODO ...\n",
    "            num_lst.append(str(i))\n",
    "            tmp_ner_dict[num_lst[i] + '号企业'] = ner\n",
    "\n",
    "        s = s.replace(ner, num_lst[i] + '号企业')\n",
    "    return s, tmp_ner_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_tag_par(s):\n",
    "    \"\"\"\n",
    "    do segment, postag and parse\n",
    "    \"\"\"\n",
    "    words = segmentor.segment(s)\n",
    "    tags = postagger.postag(words)\n",
    "    arcs = parser.parse(words, tags)\n",
    "    arcs_lst = list(map(list, zip(*[[arc[0], arc[1]] for arc in arcs])))\n",
    "    parse_result = pd.DataFrame([[a, b, c, d] for a, b, c, d in zip(list(words), list(tags), arcs_lst[0], arcs_lst[1])],\n",
    "                                    index=range(1, len(words) + 1))\n",
    "    return words, tags, arcs, arcs_lst, parse_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sen_tag(l_w, parse_result,  str_enti):\n",
    "    \"\"\"\n",
    "    find the sentence tag type of entity1 and entity2\n",
    "    -1 means we do not support this type\n",
    "    \"\"\"\n",
    "    tag_type = -1 \n",
    "\n",
    "    entity_index = l_w.index(str_enti)\n",
    "    entity_sentence_type = parse_result.iloc[entity_index, -1]\n",
    "    if entity_sentence_type in SEN_TAGS:\n",
    "        tag_type = SEN_TAGS.index(entity_sentence_type)\n",
    "    return tag_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keyword(words):\n",
    "    \"\"\"\n",
    "    find the type of keyword in words\n",
    "    \"\"\"\n",
    "    k_w = None\n",
    "    for w in words:\n",
    "        if w in key_words:\n",
    "            k_w = w\n",
    "            break\n",
    "    return k_w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(s, isGraph = False):\n",
    "    \"\"\"\n",
    "    do dependency syntactic parsing and return the relative five feature vectors\n",
    "    \"\"\"\n",
    "    s, tmp_ner_dict = name_entity_modification(s)\n",
    "    words, tags, arcs, arcs_lst, parse_result = seg_tag_par(s)\n",
    "    \n",
    "    result = []\n",
    "    rely_id = [arc[0] for arc in arcs]  \n",
    "    relation = [arc[1] for arc in arcs]  \n",
    "    heads = ['Root' if id == 0 else words[id - 1] for id in rely_id] \n",
    "    company_list = list(tmp_ner_dict.keys())\n",
    "    str_enti_1 = \"一号企业\"\n",
    "    str_enti_2 = \"二号企业\"\n",
    "    l_w = list(words)\n",
    "    is_two_company = str_enti_1 in l_w and str_enti_2 in l_w\n",
    "    \n",
    "    # add sen_tag_type features\n",
    "    tag_type_1 = -1\n",
    "    tag_type_2 = -1\n",
    "    if is_two_company:\n",
    "        tag_type_1 = find_sen_tag(l_w, parse_result, str_enti_1)\n",
    "        tag_type_2 = find_sen_tag(l_w, parse_result, str_enti_2)\n",
    "    result.append(tag_type_1) \n",
    "    result.append(tag_type_2)    \n",
    "        \n",
    "    # add syntactic distance between two entities\n",
    "    distance_syntactic = 0\n",
    "    if is_two_company:\n",
    "        distance_syntactic = shortest_path(parse_result, list(words), str_enti_1, str_enti_2, isGraph=False)\n",
    "    result.append(distance_syntactic)\n",
    "    \n",
    "    # add absolute distance between entities\n",
    "    distance_entity = 0\n",
    "    if is_two_company:\n",
    "        distance_entity = np.abs(l_w.index(str_enti_1) - l_w.index(str_enti_2))\n",
    "    result.append(distance_entity)\n",
    "    \n",
    "    # add distance\n",
    "    k_w = find_keyword(words)\n",
    "    dis_key_e_1 = -1\n",
    "    dis_key_e_2 = -1\n",
    "\n",
    "    if k_w != None and is_two_company:\n",
    "        k_w = str(k_w)\n",
    "        l_w = list(words)\n",
    "        dis_key_e_1 = np.abs(l_w.index(str_enti_1) - l_w.index(k_w))\n",
    "        dis_key_e_2 = np.abs(l_w.index(str_enti_2) - l_w.index(k_w))\n",
    "    result.append(dis_key_e_1)\n",
    "    result.append(dis_key_e_2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(s):\n",
    "    \"\"\"\n",
    "    input corpus and return features(tf_idf and dependency syntactic parsing features)\n",
    "    \"\"\"\n",
    "    sen_feature = []\n",
    "    len_s = len(s)\n",
    "    for i in trange(len_s):\n",
    "        f_e = parse(s[i], isGraph = False)\n",
    "        sen_feature.append(f_e)\n",
    "\n",
    "    sen_feature = np.array(sen_feature)\n",
    "\n",
    "    features = np.concatenate((X_tfidf,  sen_feature), axis= 1)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [00:09<00:00, 131.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ... 18. -1. -1.]\n",
      " [ 0.  0.  0. ... 16. -1. -1.]\n",
      " [ 0.  0.  0. ...  2.  1.  3.]\n",
      " ...\n",
      " [ 0.  0.  0. ... 10. 15.  5.]\n",
      " [ 0.  0.  0. ...  2. -1. -1.]\n",
      " [ 0.  0.  0. ... 10. -1. -1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate features of \n",
    "f_v_s_path = \"../data/feature_vector.npy\"\n",
    "is_exist_f_v = os.path.exists(f_v_s_path)\n",
    "features = []\n",
    "if not is_exist_f_v:\n",
    "    features = get_feature(corpus_parse)\n",
    "    np.save(f_v_s_path, features)\n",
    "else:\n",
    "    features = np.load(f_v_s_path)\n",
    "\n",
    "features_train = features[:len(train_data), :]\n",
    "segmentor.release()\n",
    "postagger.release()\n",
    "parser.release()\n",
    "print(features_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build classifier to obtain the labels of the test set\n",
    "Using the collected feature vectors to train a classifier and do parameters searching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "seed = 9000\n",
    "\n",
    "y = train_data.loc[:, ['tag']]\n",
    "y = np.array(y.values)\n",
    "y = y.reshape(-1)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(features_train,  y, test_size = 0.2, random_state = seed)\n",
    "\n",
    "def logistic_class(Xtrain, Xtest, ytrain, ytest):\n",
    "    cross_validator = KFold(n_splits=10, shuffle=True, random_state = seed)\n",
    "\n",
    "    lr = LogisticRegression(penalty = \"l1\", solver='liblinear')\n",
    "\n",
    "    params = {\"C\":[0.1,1.0,10.0,15.0,20.0,30.0,40.0,50.0]}\n",
    "\n",
    "    grid = GridSearchCV(estimator=lr, param_grid = params, cv=cross_validator)\n",
    "    grid.fit(Xtrain, ytrain)\n",
    "    print(\"best parameters：\",grid.best_params_)\n",
    "    model = grid.best_estimator_\n",
    "    y_pred = model.predict(Xtest)\n",
    "\n",
    "    y_test = [str(value) for value in ytest]\n",
    "    y_pred = [str(value) for value in y_pred]\n",
    "\n",
    "#     train_score = model.score(Xtrain, ytrain)\n",
    "#     print(\"train_score\", train_score)\n",
    "#     test_score = model.score(Xtest, ytest)\n",
    "#     print(\"test_score\", test_score)\n",
    "\n",
    "\n",
    "    proba_value = model.predict_proba(Xtest)\n",
    "    p = proba_value[:,1]\n",
    "    print(\"Logistic=========== ROC-AUC score: %.3f\" % roc_auc_score(y_test, p))\n",
    "\n",
    "    report = classification_report(y_pred=y_pred,y_true=y_test)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters： {'C': 20.0}\n",
      "train_score 1.0\n",
      "test_score 0.9235294117647059\n",
      "Logistic=========== ROC-AUC score: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       145\n",
      "           1       0.83      0.60      0.70        25\n",
      "\n",
      "    accuracy                           0.92       170\n",
      "   macro avg       0.88      0.79      0.83       170\n",
      "weighted avg       0.92      0.92      0.92       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_model = logistic_class(Xtrain, Xtest, ytrain, ytest)\n",
    "\n",
    "features_test = features[len(train_data):, :]\n",
    "y_pred_test = s_model.predict(features_test)\n",
    "\n",
    "l_X_test_ner = X_test.values.tolist()\n",
    "\n",
    "entity_dict = {}\n",
    "relation_list = []\n",
    "\n",
    "for i, label in enumerate(y_pred_test):\n",
    "    if label == 1:\n",
    "        cur_ner_content = str(l_X_test_ner[i])\n",
    "\n",
    "        ner_list = list(set(re.findall(r'(ner\\_\\d\\d\\d\\d\\_)',cur_ner_content)))\n",
    "        if len(ner_list) == 2:\n",
    "            # print(ner_list)\n",
    "            r_e_l = []\n",
    "            for i, ner in enumerate(ner_list):\n",
    "                split_list = str.split(ner, \"_\")\n",
    "                if len(split_list) == 3:\n",
    "                    ner_id = int(split_list[1])\n",
    "\n",
    "                    if ner_id in ner_dict_reverse_new:\n",
    "                        if ner_id not in entity_dict:\n",
    "\n",
    "                            company_main_name = ner_dict_reverse_new[ner_id]\n",
    "\n",
    "                            if company_main_name in dict_entity_name_unify:\n",
    "                                entity_dict[ner_id] = company_main_name + dict_entity_name_unify[company_main_name]\n",
    "                            else:\n",
    "                                entity_dict[ner_id] = company_main_name\n",
    "\n",
    "                        r_e_l.append(ner_id)\n",
    "            if len(r_e_l) == 2:\n",
    "                relation_list.append(r_e_l)\n",
    "\n",
    "\n",
    "entity_list = [[item[0], item[1]] for item in entity_dict.items()]\n",
    "pd_enti = pd.DataFrame(np.array(entity_list), columns=['实体编号','实体名'])\n",
    "\n",
    "\n",
    "pd_re = pd.DataFrame(np.array(relation_list), columns=['实体1','实体2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>实体编号</th>\n",
       "      <th>实体名</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>氟化工|多氟多化工股份有限公司|多氟多化工股份有限公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>李云峰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006</td>\n",
       "      <td>山东华鹏玻璃|山东华鹏玻璃股份有限公司|山东华鹏玻璃股份有限公司|山东华鹏玻璃股份有限公司|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>张德华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>肖文革</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1590</td>\n",
       "      <td>赵笃学</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1602</td>\n",
       "      <td>美康生物科技股份|美康生物科技股份有限公司|美康生物科技股份有限公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1603</td>\n",
       "      <td>邹炳德</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1644</td>\n",
       "      <td>湖南天润数字娱乐文化传媒|湖南天润数字娱乐文化传媒股份有限公司|湖南天润数字娱乐文化传媒股份...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1645</td>\n",
       "      <td>广东恒润互兴资产管理|广东恒润互兴资产管理有限公司|广东恒润互兴资产管理有限公司</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     实体编号                                                实体名\n",
       "0    1002                        氟化工|多氟多化工股份有限公司|多氟多化工股份有限公司\n",
       "1    1003                                                李云峰\n",
       "2    1006  山东华鹏玻璃|山东华鹏玻璃股份有限公司|山东华鹏玻璃股份有限公司|山东华鹏玻璃股份有限公司|...\n",
       "3    1007                                                张德华\n",
       "4    1009                                                肖文革\n",
       "..    ...                                                ...\n",
       "107  1590                                                赵笃学\n",
       "108  1602                 美康生物科技股份|美康生物科技股份有限公司|美康生物科技股份有限公司\n",
       "109  1603                                                邹炳德\n",
       "110  1644  湖南天润数字娱乐文化传媒|湖南天润数字娱乐文化传媒股份有限公司|湖南天润数字娱乐文化传媒股份...\n",
       "111  1645           广东恒润互兴资产管理|广东恒润互兴资产管理有限公司|广东恒润互兴资产管理有限公司\n",
       "\n",
       "[112 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_enti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>实体1</th>\n",
       "      <th>实体2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1009</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1012</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1580</td>\n",
       "      <td>1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1582</td>\n",
       "      <td>1581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1590</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1602</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1644</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     实体1   实体2\n",
       "0   1002  1003\n",
       "1   1006  1007\n",
       "2   1009  1008\n",
       "3   1012  1013\n",
       "4   1018  1019\n",
       "..   ...   ...\n",
       "57  1580  1579\n",
       "58  1582  1581\n",
       "59  1590  1346\n",
       "60  1602  1603\n",
       "61  1644  1645\n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1002, '氟化工|多氟多化工股份有限公司|多氟多化工股份有限公司'],\n",
       " [1003, '李云峰'],\n",
       " [1006, '山东华鹏玻璃|山东华鹏玻璃股份有限公司|山东华鹏玻璃股份有限公司|山东华鹏玻璃股份有限公司|山东华鹏玻璃股份有限公司'],\n",
       " [1007, '张德华'],\n",
       " [1009, '肖文革'],\n",
       " [1008, '印纪娱乐传媒|印纪娱乐传媒股份有限公司'],\n",
       " [1012, '上海新朋实业|上海新朋实业股份有限公司'],\n",
       " [1013, '宋琳'],\n",
       " [1018, '百川能源|百川能源股份有限公司|百川能源股份有限公司'],\n",
       " [1019, '曹飞'],\n",
       " [1021, '颜军'],\n",
       " [1020, '珠海欧比特控制工程|珠海欧比特控制工程股份有限公司'],\n",
       " [1023, '宋睿'],\n",
       " [1022, '成都云图|成都云图控股股份有限公司'],\n",
       " [1026, '广州阳普医疗科技股份|广州阳普医疗科技股份有限公司|广州阳普医疗科技股份有限公司'],\n",
       " [1027, '邓冠华'],\n",
       " [1032, '厦门金达威集团股份|厦门金达威集团股份有限公司'],\n",
       " [1033, '江斌'],\n",
       " [1015, '康力电梯|康力电梯股份有限公司|康力电梯股份有限公司'],\n",
       " [1014, '王友林'],\n",
       " [1034, '东方日升新能源|东方日升新能源股份有限公司'],\n",
       " [1035, '林海峰'],\n",
       " [1036, '神州数码集团股份|神州数码集团股份有限公司'],\n",
       " [1038, '云科服务'],\n",
       " [1040, '吴宏亮'],\n",
       " [1039, '浙江唐德影视|浙江唐德影视股份有限公司'],\n",
       " [1060, '周福海'],\n",
       " [1059, '江苏亚太轻合金科技股份|江苏亚太轻合金科技股份有限公司'],\n",
       " [1067, '金浦钛业|金浦钛业股份有限公司|金浦钛业股份有限公司|金浦钛业股份有限公司'],\n",
       " [1068, '郭金东'],\n",
       " [1094, '刘梦龙'],\n",
       " [1093, '深圳市易尚展示|深圳市易尚展示股份有限公司|深圳市易尚展示股份有限公司|深圳市易尚展示股份有限公司'],\n",
       " [1133, '康美保险'],\n",
       " [1134, '康美健康保险|康美健康保险股份有限公司'],\n",
       " [1137, '天津金岸重工|天津金岸重工有限公司|天津金岸重工有限公司'],\n",
       " [1136, '天津港|天津港股份有限公司|天津港股份有限公司'],\n",
       " [1141, '澄星|澄星集团'],\n",
       " [1140, '江苏澄星磷化工|江苏澄星磷化工股份有限公司'],\n",
       " [1062, '谭颂斌'],\n",
       " [1061, '广东银禧科技股份|广东银禧科技股份有限公司|广东银禧科技股份有限公司'],\n",
       " [1191, '兴民智通|兴民智通（集团）股份有限公司'],\n",
       " [1192, '王志成'],\n",
       " [1223, '天堂硅谷'],\n",
       " [1224, '天堂硅谷 '],\n",
       " [1236, '江苏保千里视像科技集团股份|江苏保千里视像科技集团股份有限公司'],\n",
       " [1237, '庄敏'],\n",
       " [1251, '桐昆|桐昆控股|桐昆控股|桐昆控股|桐昆控股|桐昆股份|桐昆控股|桐昆控股|桐昆控股'],\n",
       " [1252, '桐昆集团股份 限|桐昆集团股份有 限公司'],\n",
       " [1255, '深圳金信诺高新技术|深圳金信诺高新技术股份有限公司'],\n",
       " [1256, '黄昌华'],\n",
       " [1277, '天津振港通信工程|天津振港通信工程有限公司'],\n",
       " [1278, '重庆博腾制药科技股份|重庆博腾制药科技股份有限公司'],\n",
       " [1279, '重庆润生科技|重庆润生科技有限公司'],\n",
       " [1284, '美好置业集团股份|美好置业集团股份有限公司'],\n",
       " [1285, '刘道明'],\n",
       " [1326, '上海远望谷信息技术|远望谷（上海）信息技术有限公司'],\n",
       " [1325, '顾清'],\n",
       " [1329, '长江电力'],\n",
       " [1330, '广州集团股份|广州发展集团股份有限公司'],\n",
       " [1331, '中华人民共和国|中华人民共和国公司|中华人民共和国公司|中华人民共和国公司'],\n",
       " [1139, '友网络科技股份|友网络科技股份有限公司|友网络科技股份有限公司'],\n",
       " [1346, '山东矿机集团股份|山东矿机集团股份有限公司|山东矿机集团股份有限公司'],\n",
       " [1347, '赵华涛'],\n",
       " [1349, '陈志江'],\n",
       " [1348, '福建纳川管材科技股份|福建纳川管材科技股份有限公司'],\n",
       " [1358, '德稻资产|德稻资产公司|德稻资产公司'],\n",
       " [1359, '北京银杏树信息技术服务 |银杏树信息技术服务(北京) 有限公司'],\n",
       " [1388, '新华联|新华联控股'],\n",
       " [1387, '新华联文化旅游|新华联文化旅游发展股份有限公司'],\n",
       " [1391, '深圳市赢时胜信息技术|深圳市赢时胜信息技术股份有限公司'],\n",
       " [1392, '唐球'],\n",
       " [1396, '飞乐|飞乐股份'],\n",
       " [1397, '仪电电子|仪电电子集团'],\n",
       " [1429, '格林美|格林美股份有限公司'],\n",
       " [1430, '陈星题'],\n",
       " [1439, '杭州中恒电气|杭州中恒电气股份有限公司'],\n",
       " [1440, '朱国锭'],\n",
       " [1207, '天泰|天泰公司|天泰公司|天泰公司|天泰公司|天泰公司'],\n",
       " [1445, '宁武榆 树坡煤业|宁武榆 树坡煤业有限公司'],\n",
       " [1460, '吉林敖东药业集团股份|吉林敖东药业集团股份有限公司'],\n",
       " [1090, '广发证券|广发证券股份有限公司|广发证券股份有限公司|广发证券股份有限公司|广发证券股份有限公司'],\n",
       " [1461, '哈尔滨秋林集团股份|哈尔滨秋林集团股份有限公司|哈尔滨秋林集团股份有限公司|哈尔滨秋林集团股份有限公司|哈尔滨秋林集团股份有限公司'],\n",
       " [1249, '秋林|秋林集团|秋林集团|秋林集团|秋林集团|秋林集团|秋林集团|秋林集团|秋林集团|秋林集团|秋林集团|秋林集团'],\n",
       " [1477, '叶仙玉'],\n",
       " [1476, '浙江星星科技股份|浙江星星科技股份有限公司|浙江星星科技股份有限公司|浙江星星科技股份有限公司|浙江星星科技股份有限公司'],\n",
       " [1492, '民盛金科|民盛金科控股股份有限公司|民盛金科控股股份有限公司'],\n",
       " [1493, '浙江泰晟新材料科技|浙江泰晟新材料科技有限公司|浙江泰晟新材料科技有限公司'],\n",
       " [1496, '深圳市尚荣医疗|深圳市尚荣医疗股份有限公司'],\n",
       " [1497, '梁桂秋'],\n",
       " [1504, '黎阳装备|黎阳装备公司'],\n",
       " [1503, '贵州黎阳装备科技|贵州黎阳装备科技发展有限公司'],\n",
       " [1512, '邢翰学'],\n",
       " [1511, '浙江开尔新材料|浙江开尔新材料股份有限公司'],\n",
       " [1523, '上海大众企业管理|上海大众企业管理有限公司'],\n",
       " [1524, '大众交通|大众交通(集团)股份有限公司'],\n",
       " [1529, '福星|福星集团'],\n",
       " [1528, '湖北福星科技股份|湖北福星科技股份有限公司'],\n",
       " [1537, '靳晓堂'],\n",
       " [1536, '上海北特科技股份|上海北特科技股份有限公司'],\n",
       " [1539, '同煤|同煤集团'],\n",
       " [1540, '山西漳泽电力|山西漳泽电力股份有限公司'],\n",
       " [1563, '华斯|华斯控股股份有限公司'],\n",
       " [1564, '贺国英'],\n",
       " [1580, '浙报|浙报控股'],\n",
       " [1579, '浙报数字文化集团股份|浙报数字文化集团股份有限公司'],\n",
       " [1582, '柳州医药'],\n",
       " [1581, '广西柳州医药|广西柳州医药股份有限公司|广西柳州医药股份有限公司'],\n",
       " [1590, '赵笃学'],\n",
       " [1602, '美康生物科技股份|美康生物科技股份有限公司|美康生物科技股份有限公司'],\n",
       " [1603, '邹炳德'],\n",
       " [1644, '湖南天润数字娱乐文化传媒|湖南天润数字娱乐文化传媒股份有限公司|湖南天润数字娱乐文化传媒股份有限公司'],\n",
       " [1645, '广东恒润互兴资产管理|广东恒润互兴资产管理有限公司|广东恒润互兴资产管理有限公司']]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1002, 1003],\n",
       " [1006, 1007],\n",
       " [1009, 1008],\n",
       " [1012, 1013],\n",
       " [1018, 1019],\n",
       " [1021, 1020],\n",
       " [1023, 1022],\n",
       " [1026, 1027],\n",
       " [1002, 1003],\n",
       " [1032, 1033],\n",
       " [1015, 1014],\n",
       " [1034, 1035],\n",
       " [1036, 1038],\n",
       " [1040, 1039],\n",
       " [1026, 1027],\n",
       " [1060, 1059],\n",
       " [1067, 1068],\n",
       " [1067, 1068],\n",
       " [1094, 1093],\n",
       " [1133, 1134],\n",
       " [1137, 1136],\n",
       " [1141, 1140],\n",
       " [1062, 1061],\n",
       " [1191, 1192],\n",
       " [1223, 1224],\n",
       " [1236, 1237],\n",
       " [1251, 1252],\n",
       " [1255, 1256],\n",
       " [1277, 1136],\n",
       " [1278, 1279],\n",
       " [1284, 1285],\n",
       " [1094, 1093],\n",
       " [1326, 1325],\n",
       " [1329, 1330],\n",
       " [1331, 1139],\n",
       " [1346, 1347],\n",
       " [1349, 1348],\n",
       " [1358, 1359],\n",
       " [1388, 1387],\n",
       " [1391, 1392],\n",
       " [1396, 1397],\n",
       " [1429, 1430],\n",
       " [1439, 1440],\n",
       " [1207, 1445],\n",
       " [1460, 1090],\n",
       " [1461, 1249],\n",
       " [1477, 1476],\n",
       " [1492, 1493],\n",
       " [1496, 1497],\n",
       " [1504, 1503],\n",
       " [1512, 1511],\n",
       " [1523, 1524],\n",
       " [1529, 1528],\n",
       " [1537, 1536],\n",
       " [1539, 1540],\n",
       " [1563, 1564],\n",
       " [1477, 1476],\n",
       " [1580, 1579],\n",
       " [1582, 1581],\n",
       " [1590, 1346],\n",
       " [1602, 1603],\n",
       " [1644, 1645]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building a graph graph to represent the dug relationships between different entities.\n",
    "Here, we use cypher language and NoSQL(noe4j graph database) to do insert/delete/query operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert data into graph\n",
    "from py2neo import Node, Relationship, Graph\n",
    "graph = Graph(\n",
    "    \"http://localhost:7474\",\n",
    "    username=\"project3\",\n",
    "    password = \"password\"\n",
    ")\n",
    "graph.delete_all()\n",
    "\n",
    "for v in relation_list:\n",
    "    a = Node('Company', name=str(v[0]))\n",
    "    b = Node('Company', name=str(v[1]))\n",
    "\n",
    "    #undirectional edge\n",
    "    r = Relationship(a, 'INVEST', b)\n",
    "    s = a | b | r\n",
    "    graph.create(s)\n",
    "    r = Relationship(b, 'INVEST', a)\n",
    "    s = a | b | r\n",
    "    graph.create(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_3_layers_relationship():\n",
    "    \"\"\"\n",
    "    check whether it exits three-layer relationships or not a invest b, b invest c ---> a invest c\n",
    "    \"\"\"\n",
    "    import random\n",
    "\n",
    "    result_2 = []\n",
    "    result_3 = []\n",
    "    for value in entity_list:\n",
    "        ner_id = value[0]\n",
    "        str_sql_3 = \"match data=(na:Company{{name:'{0}'}})-[:INVEST]->(nb:Company)-[:INVEST]->(nc:Company) where na.name <> nc.name return data\".format(str(ner_id))\n",
    "        result_3 = graph.run(str_sql_3).data()\n",
    "        if len(result_3) > 0:\n",
    "            break\n",
    "\n",
    "    if len(result_3) > 0:\n",
    "        print(\"step1\")\n",
    "        print(result_3)\n",
    "    else:\n",
    "        print(\"step2\")\n",
    "        random_index = random.randint(0, len(entity_list) - 1)\n",
    "        random_ner_id = entity_list[random_index][0]\n",
    "        str_sql_2 = \"match data=(na:Company{{name:'{0}'}})-[*2]->(nb:Company) return data\".format(str(random_ner_id))\n",
    "        result_2 = graph.run(str_sql_2).data()\n",
    "        print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step2\n",
      "[{'data': Path(Node('Company', name='1039'), INVEST(Node('Company', name='1039'), Node('Company', name='1040')), INVEST(Node('Company', name='1040'), Node('Company', name='1039')))}]\n"
     ]
    }
   ],
   "source": [
    "check_3_layers_relationship()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entity DISAMBIGUATION\n",
    "After representing the entities' relationships in the graph database, we would like to learn more about the found entities. But how could we distinguish the entities appearing in our dataset from the ones we found on the search engine. baike.baidu.com, like Wikipedia, provides polysemantic sections, which stores existing similar terms. Our goal is to compare the cosine similarity of the tf-idf vectors between the entities in the polysemantic list and the given datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train tf_idf\n",
    "test_data_dis = pd.read_csv('../data/info_extract/test_data.csv', encoding = 'gb2312', header=0)\n",
    "list_person_content = {}\n",
    "window = 5\n",
    "\n",
    "LTP_DATA_DIR = './ltp_data_v3.4/ltp_data_v3.4.0'\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')\n",
    "segmentor = Segmentor(cws_model_path, lexicon_path = '../data/user_dict.txt') \n",
    "\n",
    "f = lambda x: ' '.join([word for word in segmentor.segment(x)])\n",
    "f2 = lambda x: re.compile(\"[^\\u4e00-\\u9fa5]\").sub('', x)\n",
    "corpus_dis = test_data['sentence'].map(f).map(f2).tolist()\n",
    "vectorizer = TfidfVectorizer()  \n",
    "X_tfidf = vectorizer.fit_transform(corpus_dis).toarray()  \n",
    "\n",
    "# get entity\n",
    "for i in range(25):\n",
    "    sentence = corpus_dis[i]\n",
    "    len_sen = len(sentence)\n",
    "    words, ners = fool.analysis(sentence)\n",
    "    for start, end, ner_type, ner_name in ners[0]:\n",
    "        if ner_type == 'person':\n",
    "\n",
    "            start_index = max(0, start - window)\n",
    "            end_index = min(len_sen - 1, end - 1 + window)\n",
    "            left_str = sentence[start_index:start]\n",
    "            right_str = sentence[end - 1:end_index]\n",
    "\n",
    "            left_str = ' '.join([word for word in segmentor.segment(left_str)])\n",
    "            right_str = ' '.join([word for word in segmentor.segment(right_str)])\n",
    "            new_str = left_str + \" \" +right_str\n",
    "\n",
    "\n",
    "            content_vec = vectorizer.transform([new_str])\n",
    "\n",
    "            ner_id = ner_dict_new[ner_name]\n",
    "            if ner_id not in list_person_content:\n",
    "                list_person_content[ner_id] = content_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1003: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1005: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1007: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1009: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1011: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1013: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1014: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1016: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1019: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1021: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1023: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1027: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1028: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1031: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1033: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1035: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1037: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1040: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1042: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1046: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 1050: <1x412 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_person_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_para_vector(para_elems):\n",
    "    str_res = \"\"\n",
    "    for p_e in para_elems:\n",
    "        petext = re.sub(r'(\\r|\\n)*', '', p_e.text)\n",
    "        petext = re.compile(\"[^\\u4e00-\\u9fa5]\").sub('', petext)\n",
    "        str_res += petext\n",
    "    str_res = ' '.join([word for word in jieba.cut(str_res)])\n",
    "    content_vec = vectorizer.transform([str_res])\n",
    "    content_vec = content_vec.toarray()[0]\n",
    "    return content_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [11:25<00:00, 32.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1003, '李云峰', 'https://baike.baidu.com/item/%E6%9D%8E%E4%BA%91%E5%B3%B0/13011276'], [1005, '侯毅', 'https://baike.baidu.com/item/%E4%BE%AF%E6%AF%85/3417673'], [1007, '张德华', 'https://baike.baidu.com/item/%E5%BC%A0%E5%BE%B7%E5%8D%8E/12640205'], [1009, '肖文革', 'https://baike.baidu.com/item/%E8%82%96%E6%96%87%E9%9D%A9/12761874'], [1011, '熊海涛', 'https://baike.baidu.com/item/%E7%86%8A%E6%B5%B7%E6%B6%9B/10849366'], [1013, '宋琳', 'https://baike.baidu.com/item/%E5%AE%8B%E7%90%B3/3967064'], [1014, '王友林', 'https://baike.baidu.com/item/%E7%8E%8B%E5%8F%8B%E6%9E%97/71412'], [1016, '彭聪', 'https://baike.baidu.com/item/%E5%BD%AD%E8%81%AA/19890127'], [1019, '曹飞', 'https://baike.baidu.com/item/%E6%9B%B9%E9%A3%9E/10396036'], [1021, '颜军', 'https://baike.baidu.com/item/%E9%A2%9C%E5%86%9B/3476040'], [1023, '宋睿', 'https://baike.baidu.com/item/%E5%AE%8B%E7%9D%BF/2629451'], [1027, '邓冠华', 'https://baike.baidu.com/item/%E9%82%93%E5%86%A0%E5%8D%8E'], [1028, '孙锋峰', 'https://baike.baidu.com/item/%E5%AD%99%E9%94%8B%E5%B3%B0'], [1031, '林奇', 'https://baike.baidu.com/item/%E6%9E%97%E5%A5%87/53180'], [1033, '江斌', 'https://baike.baidu.com/item/%E6%B1%9F%E6%96%8C/64335'], [1035, '林海峰', 'https://baike.baidu.com/item/%E6%9E%97%E6%B5%B7%E5%B3%B0'], [1037, '郭为', 'https://baike.baidu.com/item/%E9%83%AD%E4%B8%BA/77150'], [1040, '吴宏亮', 'https://baike.baidu.com/item/%E5%90%B4%E5%AE%8F%E4%BA%AE/1488540'], [1042, '王利平', 'https://baike.baidu.com/item/%E7%8E%8B%E5%88%A9%E5%B9%B3/3273251'], [1046, '周旭辉', 'https://baike.baidu.com/item/%E5%91%A8%E6%97%AD%E8%BE%89/9981261'], [1050, '吴艳', 'https://baike.baidu.com/item/%E5%90%B4%E8%89%B3/5951149']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "from requests_html import HTML\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import jieba\n",
    "\n",
    "\n",
    "list_company_names = [company for value in entity_list for company in str.split(value[1], \"|\")]\n",
    "\n",
    "\n",
    "list_person_url = []\n",
    "url_prefix = \"https://baike.baidu.com/item/\"\n",
    "url_error = \"https://baike.baidu.com/error.html\"\n",
    "\n",
    "l_p_items = list(list_person_content.items())\n",
    "len_items = len(l_p_items)\n",
    "\n",
    "\n",
    "for index in trange(len_items):\n",
    "    value = l_p_items[index]\n",
    "\n",
    "    person_id = value[0]\n",
    "    vector_entity = csr_matrix(value[1])\n",
    "\n",
    "    person_name = ner_dict_reverse_new[person_id]\n",
    "\n",
    "    session = HTMLSession()\n",
    "    url = url_prefix + person_name\n",
    "    response = session.get(url)\n",
    "\n",
    "    url_list = []\n",
    "    if response.url != url_error:\n",
    "        para_elems = response.html.find('.para')\n",
    "        content_vec = get_para_vector(para_elems)\n",
    "        url_list.append([response.url, content_vec])\n",
    "\n",
    "        banks = response.html.find('.polysemantList-wrapper')\n",
    "\n",
    "        if len(banks) > 0:\n",
    "            banks_child = banks[0]\n",
    "            persion_links = list(banks_child.absolute_links)\n",
    "            for link in persion_links:\n",
    "                r_link = session.get(link)\n",
    "\n",
    "                if r_link.url == url_error:\n",
    "                    continue\n",
    "\n",
    "                para_elems = r_link.html.find('.para')\n",
    "                content_vec = get_para_vector(para_elems)\n",
    "                url_list.append([r_link.url, content_vec])\n",
    "\n",
    "        vectorizer_list = [item[1] for item in url_list]\n",
    "        vectorizer_list = csr_matrix(vectorizer_list)\n",
    "        result = list(cosine_similarity(value[1], vectorizer_list)[0])\n",
    "        max_index = result.index(max(result))\n",
    "        list_person_url.append([person_id, person_name, url_list[max_index][0]])\n",
    "\n",
    "print(list_person_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
