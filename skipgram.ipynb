{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data is from http://mattmahoney.net/dc/text8.zip\n",
    "EMBEDDING_DIM = embedding_dim = 128 \n",
    "PRINT_EVERY = 100 # print frequency\n",
    "EPOCHES = 1000 \n",
    "BATCH_SIZE = 5 \n",
    "N_SAMPLES = n_samples = 3 \n",
    "WINDOW_SIZE = 5 \n",
    "FREQ = 5 #threshold for word's frequency\n",
    "DELETE_WORDS = False #delete words with high frequent\n",
    "VOCABULARY_SIZE = 50000\n",
    "re_pats = [r'[?|!|\\'|\"#]',r'[.|,|)|(|\\|/]']\n",
    "t=1e-5 #used in remove high frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text8.train.txt\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    for re_pattern in re_pats:\n",
    "        text = re.sub(re_pattern, \" \", text)\n",
    "    words = text.split()\n",
    "    words_counts = Counter(words)\n",
    "    trimmed_words = [word for word in words if words_counts[word] > FREQ]\n",
    "    return trimmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism', 'originated', 'as', 'a', 'term']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare dictionary, frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(words)\n",
    "vocab2int = {w: c for c, w in enumerate(vocab)}\n",
    "int2vocab = {c: w for c, w in enumerate(vocab)}\n",
    "int_words = [vocab2int[w] for w in words]\n",
    "int_word_counts = Counter(int_words)\n",
    "total_count = len(int_words)\n",
    "word_freqs = {w: c/total_count for w, c in int_word_counts.items() }\n",
    "prob_drop = {w: 1-np.sqrt(t/word_freqs[w]) for w in int_word_counts}\n",
    "train_words = [w for w in int_words if random.random()<(1-prob_drop[w])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(words, idx):\n",
    "    target_window = np.random.randint(1, WINDOW_SIZE + 1)\n",
    "    start_point = idx-target_window if (idx - target_window) > 0 else 0\n",
    "    end_point = idx + target_window\n",
    "    targets = set(words[start_point:idx] + words[idx+1:end_point+1])\n",
    "    return list(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(words):\n",
    "    n_batches = len(words)//BATCH_SIZE\n",
    "    words = words[:n_batches*BATCH_SIZE]\n",
    "    for idx in range(0, len(words), BATCH_SIZE):\n",
    "        batch_x, batch_y = [], []\n",
    "        batch = words[idx:idx+BATCH_SIZE]\n",
    "        for i in range(len(batch)):\n",
    "            x = batch[i]\n",
    "            y = get_target(batch, i)\n",
    "            batch_x.extend([x] * len(y))\n",
    "            batch_y.extend(y)\n",
    "            yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramNeg(nn.Module):\n",
    "    def __init__(self, n_vocab, n_embed, noise_dist = None):\n",
    "        super().__init__()\n",
    "        self.n_vocab = n_vocab\n",
    "        self.n_embed = n_embed\n",
    "        self.noise_dist = noise_dist\n",
    "        \n",
    "        # in for center words, out for neighbors words\n",
    "        self.in_embed = nn.Embedding(n_vocab, n_embed)\n",
    "        self.out_embed = nn.Embedding(n_vocab, n_embed)\n",
    "        self.in_embed.weight.data.uniform_(-1,1)\n",
    "        self.out_embed.weight.data.uniform_(-1,1)\n",
    "    def forward_input(self, input_words):\n",
    "        input_vector = self.in_embed(input_words)\n",
    "        return input_vector\n",
    "    def forward_output(self, output_words):\n",
    "        output_vector = self.out_embed(output_words)\n",
    "        return output_vector\n",
    "    # do negative sampling based on given noise_dist\n",
    "    def forward_noise(self,var_batch_size):\n",
    "        if self.noise_dist is None:\n",
    "            noise_dist = torch.ones(self.n_vocab)\n",
    "        else:\n",
    "            noise_dist = self.noise_dist\n",
    "        noise_words = torch.multinomial(noise_dist, var_batch_size * n_samples, replacement=True)\n",
    "        noise_vectors = self.out_embed(noise_words).view(var_batch_size, n_samples, self.n_embed)\n",
    "        return noise_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate noise dist used in negative sampling\n",
    "word_freqs_array = np.array(list(word_freqs.values()))\n",
    "unigram_dist = word_freqs_array / word_freqs_array.sum()\n",
    "noise_dist = torch.from_numpy(unigram_dist ** (0.75) / np.sum(unigram_dist ** (0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5665e-05, 5.2315e-05, 3.1533e-03,  ..., 1.8826e-06, 2.3360e-06,\n",
       "        2.3360e-06], dtype=torch.float64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSamplingLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, input_vectors, output_vectors, noise_vectors):\n",
    "        batch_size, embed_size = input_vectors.shape\n",
    "        input_vectors = input_vectors.view(batch_size, embed_size, 1)\n",
    "        output_vectors = output_vectors.view(batch_size, 1, embed_size)\n",
    "        out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log()\n",
    "        out_loss = out_loss.squeeze()\n",
    "        \n",
    "        noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()\n",
    "        noise_loss = noise_loss.squeeze().sum(1)\n",
    "        return -(out_loss + noise_loss).mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128]) torch.Size([3, 128]) torch.Size([3, 3, 128])\n",
      "6.597312927246094 is current loss\n",
      "torch.Size([7, 128]) torch.Size([7, 128]) torch.Size([7, 3, 128])\n",
      "5.9126410484313965 is current loss\n",
      "torch.Size([11, 128]) torch.Size([11, 128]) torch.Size([11, 3, 128])\n",
      "6.1255412101745605 is current loss\n",
      "torch.Size([15, 128]) torch.Size([15, 128]) torch.Size([15, 3, 128])\n",
      "6.536654949188232 is current loss\n",
      "torch.Size([17, 128]) torch.Size([17, 128]) torch.Size([17, 3, 128])\n",
      "6.674886703491211 is current loss\n",
      "torch.Size([2, 128]) torch.Size([2, 128]) torch.Size([2, 3, 128])\n",
      "7.731934547424316 is current loss\n",
      "torch.Size([6, 128]) torch.Size([6, 128]) torch.Size([6, 3, 128])\n",
      "4.529255390167236 is current loss\n",
      "torch.Size([10, 128]) torch.Size([10, 128]) torch.Size([10, 3, 128])\n",
      "6.140489101409912 is current loss\n",
      "torch.Size([14, 128]) torch.Size([14, 128]) torch.Size([14, 3, 128])\n",
      "5.356362342834473 is current loss\n",
      "torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 3, 128])\n",
      "6.346285343170166 is current loss\n",
      "torch.Size([4, 128]) torch.Size([4, 128]) torch.Size([4, 3, 128])\n",
      "10.191720008850098 is current loss\n",
      "torch.Size([8, 128]) torch.Size([8, 128]) torch.Size([8, 3, 128])\n",
      "5.7694525718688965 is current loss\n",
      "torch.Size([12, 128]) torch.Size([12, 128]) torch.Size([12, 3, 128])\n",
      "6.886211395263672 is current loss\n",
      "torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 3, 128])\n",
      "5.6088104248046875 is current loss\n",
      "torch.Size([18, 128]) torch.Size([18, 128]) torch.Size([18, 3, 128])\n",
      "5.922613620758057 is current loss\n",
      "torch.Size([3, 128]) torch.Size([3, 128]) torch.Size([3, 3, 128])\n",
      "4.201887607574463 is current loss\n",
      "torch.Size([7, 128]) torch.Size([7, 128]) torch.Size([7, 3, 128])\n",
      "7.143000602722168 is current loss\n",
      "torch.Size([10, 128]) torch.Size([10, 128]) torch.Size([10, 3, 128])\n",
      "4.28061056137085 is current loss\n",
      "torch.Size([12, 128]) torch.Size([12, 128]) torch.Size([12, 3, 128])\n",
      "5.3581461906433105 is current loss\n",
      "torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 3, 128])\n",
      "7.240647315979004 is current loss\n",
      "torch.Size([4, 128]) torch.Size([4, 128]) torch.Size([4, 3, 128])\n",
      "6.605835437774658 is current loss\n",
      "torch.Size([8, 128]) torch.Size([8, 128]) torch.Size([8, 3, 128])\n",
      "6.526226997375488 is current loss\n",
      "torch.Size([12, 128]) torch.Size([12, 128]) torch.Size([12, 3, 128])\n",
      "6.672730922698975 is current loss\n",
      "torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 3, 128])\n",
      "6.217273235321045 is current loss\n",
      "torch.Size([20, 128]) torch.Size([20, 128]) torch.Size([20, 3, 128])\n",
      "7.025484561920166 is current loss\n",
      "torch.Size([4, 128]) torch.Size([4, 128]) torch.Size([4, 3, 128])\n",
      "7.064079284667969 is current loss\n",
      "torch.Size([6, 128]) torch.Size([6, 128]) torch.Size([6, 3, 128])\n",
      "5.983003616333008 is current loss\n",
      "torch.Size([8, 128]) torch.Size([8, 128]) torch.Size([8, 3, 128])\n",
      "4.865711212158203 is current loss\n",
      "torch.Size([12, 128]) torch.Size([12, 128]) torch.Size([12, 3, 128])\n",
      "5.651784896850586 is current loss\n",
      "torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 3, 128])\n",
      "5.411194801330566 is current loss\n",
      "torch.Size([3, 128]) torch.Size([3, 128]) torch.Size([3, 3, 128])\n",
      "2.9941062927246094 is current loss\n",
      "torch.Size([7, 128]) torch.Size([7, 128]) torch.Size([7, 3, 128])\n",
      "6.046448230743408 is current loss\n",
      "torch.Size([11, 128]) torch.Size([11, 128]) torch.Size([11, 3, 128])\n",
      "4.549062728881836 is current loss\n",
      "torch.Size([15, 128]) torch.Size([15, 128]) torch.Size([15, 3, 128])\n",
      "5.332315921783447 is current loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-dfaddedb20aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} is current loss\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SkipGramNeg(len(vocab2int), EMBEDDING_DIM, noise_dist=noise_dist)\n",
    "criterion = NegativeSamplingLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "steps = 0\n",
    "for e in range(EPOCHES):\n",
    "    for input_words, target_words in get_batch(train_words):\n",
    "        steps +=1\n",
    "        inputs, targets = torch.LongTensor(input_words), torch.LongTensor(target_words)\n",
    "        input_vectors = model.forward_input(inputs)\n",
    "        output_vectors = model.forward_output(targets)\n",
    "        noise_vectors = model.forward_noise(len(input_vectors))\n",
    "        print(input_vectors.size(), output_vectors.size(), noise_vectors.size())\n",
    "        \n",
    "        loss = criterion(input_vectors, output_vectors, noise_vectors)\n",
    "        if steps // PRINT_EVERY == 0:\n",
    "            print(\"{} is current loss\".format(loss))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
