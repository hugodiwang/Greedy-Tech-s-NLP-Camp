{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first project of the Greedy-tech NLP Camp. Our goal is to understand each part of the NLP task and build a retrieval-based QA system.\n",
    "The organization of this project is as follows:\n",
    "Part 1: build a word segmentation tool with the enumeration method\n",
    "part 2: apply the Viterbi algorithm to decrease the time complexity\n",
    "part 3: understand the dataset, which involves the question-answer pair\n",
    "part 4: text preprocessing\n",
    "part 5: word representation with tf-idf method\n",
    "part 6: find the top 5 answers to a testing question by comparing the testing question's cosine similarity with the questions in the data set\n",
    "part 7: apply the inverted index to decrease the time complexity\n",
    "part 8: replace the tf-idf word representation with the word2vec method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 1: build a word segmentation tool with the enumeration method \n",
    "The given data includes:\n",
    "1) one Chinese dictionary, dic.xlsx\n",
    "2) part of the words' probability. For other words' probability, if the word exists in the dictionary, then the probability is 0.00001, otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# use set to store the dictionary and check the given probability\n",
    "import pandas as pd\n",
    "dic_words = pd.read_excel('data\\dic.xlsx',header=None)   # 保存词典库中读取的单词\n",
    "dic_set = set(dic_words[0])\n",
    "print('羊肚子' in dic_set)\n",
    "\n",
    "word_prob = {\"北京\":0.03,\"的\":0.08,\"天\":0.005,\"气\":0.005,\"天气\":0.06,\"真\":0.04,\"好\":0.05,\"真好\":0.04,\"啊\":0.01,\"真好啊\":0.02, \n",
    "             \"今\":0.01,\"今天\":0.07,\"课程\":0.06,\"内容\":0.06,\"有\":0.05,\"很\":0.03,\"很有\":0.04,\"意思\":0.06,\"有意思\":0.005,\"课\":0.01,\n",
    "             \"程\":0.005,\"经常\":0.08,\"意见\":0.08,\"意\":0.01,\"见\":0.005,\"有意见\":0.02,\"分歧\":0.04,\"分\":0.02, \"歧\":0.005}\n",
    "\n",
    "print (sum(word_prob.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a naive word segmentation tool and check the results\n",
    "import math\n",
    "def word_segment_naive(input_str):\n",
    "    segments = []\n",
    "    best_score = 1e10       \n",
    "    if(len(input_str) == 0):\n",
    "        return segments\n",
    "    for i in range(1,len(input_str)+1):\n",
    "        word = input_str[0:i]\n",
    "        if word in dic_set:\n",
    "            subString = word_segment_naive(input_str[i:])\n",
    "            if(len(subString)==0):\n",
    "                segments.append([word])\n",
    "            else:\n",
    "\n",
    "                for st in subString:  \n",
    "                    st = [word] + st\n",
    "                    segments.append(st)\n",
    "    for st in segments:\n",
    "        score = 0\n",
    "        for each in st:\n",
    "            score -= math.log(word_prob.get(each,0.00001))\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_segment = st  \n",
    "\n",
    "    return [best_segment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['今天', '天气', '好']]\n",
      "[['今天', '的', '课程', '内容', '很', '有意思']]\n",
      "[['经常', '有', '意见', '分歧']]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(word_segment_naive(\"今天天气好\"))\n",
    "print(word_segment_naive(\"今天的课程内容很有意思\"))\n",
    "print(word_segment_naive(\"经常有意见分歧\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time complexity: O(n^n), space complexity: O(n^n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 2: apply the Viterbi algorithm to decrease the time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def word_segment_viterbi(input_str):\n",
    "    # use a matrix to store the pre-calculated probability\n",
    "    node_num = len(input_str) + 1\n",
    "    graph = np.zeros((node_num, node_num), dtype=int)\n",
    "    for i in range(node_num):\n",
    "        for j in range(i, node_num):\n",
    "            if i != j:\n",
    "                if word_prob.get(input_str[i:j]) is None:\n",
    "                    if j-i == 1:\n",
    "                        ratio = -math.log(0.00001)\n",
    "                    else:\n",
    "                        ratio = 0\n",
    "                else:\n",
    "                    ratio = -math.log(word_prob.get(input_str[i:j]))\n",
    "                graph[i][j] = ratio\n",
    "                \n",
    "    # use dp to solve the viterbi problem\n",
    "    dp = [10000 for _ in range(node_num)]\n",
    "    dp[0] = 0\n",
    "    path = [0 for _ in range(node_num)]\n",
    "    for i in range(1, node_num):\n",
    "        for j in range(i):\n",
    "\n",
    "            if graph[j][i] != 0:\n",
    "                if dp[j] + graph[j][i] < dp[i]:\n",
    "\n",
    "                    dp[i] = dp[j] + graph[j][i]\n",
    "                    path[i] = j\n",
    "\n",
    "    index = []\n",
    "    last = len(path)-1\n",
    "    while last != 0:\n",
    "        index.append(path[last])\n",
    "        last = path[last]\n",
    "\n",
    "    index = index[::-1]\n",
    "    best_segment = []\n",
    "    for i in range(len(index)):\n",
    "        if i == len(index) -1:\n",
    "            best_segment.append(input_str[index[i]:])\n",
    "        else:\n",
    "            best_segment.append(input_str[index[i]:index[i+1]])\n",
    "    return best_segment                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京', '的', '天气', '真好啊']\n",
      "['今天', '的', '课程', '内容', '很有', '意思']\n",
      "['经常', '有意见', '分歧']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(word_segment_viterbi(\"北京的天气真好啊\"))\n",
    "print(word_segment_viterbi(\"今天的课程内容很有意思\"))\n",
    "print(word_segment_viterbi(\"经常有意见分歧\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time complexity: O(n^3), space complexity: O(n^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential further improvement:\n",
    "1) the current probability is calculated based on the collected documents. We can consider more data to get more accurate probability\n",
    "2) one-order markov is nor precise\n",
    "3) it can not deal with polysemy\n",
    "4) if the words do not exist in the dictionary, these words can not be segmented correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 3:understand the dataset, which involves the question-answer pair\n",
    "From this part, we start build our retrieval-based QA system.\n",
    "The given data includes:\n",
    "1) dev-v2.0.json file includes the question-answer pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file and plot the data\n",
    "import json\n",
    "def read_corpus():\n",
    "    with open('data/train-v2.0.json', encoding='utf-8') as fp:\n",
    "        data = json.load(fp)\n",
    "    qlist = []; alist = []\n",
    "    for item in data[\"data\"]:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            for qa in para[\"qas\"]:\n",
    "                qlist.append(qa[\"question\"])\n",
    "                try:\n",
    "                    alist.append(qa[\"answers\"][0][\"text\"])\n",
    "                except IndexError:\n",
    "                    qlist.pop()\n",
    "                \n",
    "    assert len(qlist) == len(alist) \n",
    "    return qlist, alist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_word_total: 51841\n",
      "word_total: 874076\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "wordsCount = Counter()\n",
    "qlist, alist = read_corpus()\n",
    "for text in qlist:\n",
    "    wordsCount.update(text.strip(' .!?').split(' '))\n",
    "diff_word_total = len(wordsCount.keys())\n",
    "word_total = sum(wordsCount.values())\n",
    "print('diff_word_total:' , diff_word_total)\n",
    "print('word_total:' , word_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 words\n",
      "[['the', 60960], ['What', 36995], ['of', 33987], ['in', 21785], ['to', 18443], ['was', 17065], ['is', 16198], ['did', 15634], ['what', 13219], ['a', 10753], ['How', 8023], ['Who', 8009], ['and', 7229], ['for', 7200], ['many', 5497], ['are', 5455], ['When', 5367], ['that', 4436], ['were', 4428], ['does', 4331]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "valueSorted = sorted(wordsCount.values(),reverse=True)\n",
    "plt.figure(figsize= [8, 5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(valueSorted)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(valueSorted[0:20])\n",
    "inverseDict = dict(zip(wordsCount.values(), wordsCount.keys()))\n",
    "print(\"top 20 words\")\n",
    "print([[inverseDict[v],v] for v in valueSorted[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find the Zipf's law from the above figure.\n",
    "# The figure is similar the exponential function. The frequency of the ranked first \n",
    "# word is two times of the frequency of the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 words\n",
      "[['the', 13211], ['of', 8893], ['and', 8172], ['to', 3440], ['a', 3294], ['in', 2838], ['The', 1769], ['or', 1261], ['for', 1032], ['million', 854], ['as', 840], ['by', 801], ['is', 722], ['on', 720], ['on', 720], ['from', 696], ['that', 664], ['an', 610], ['century', 556], ['their', 536]]\n"
     ]
    }
   ],
   "source": [
    "wordCountAns = Counter()\n",
    "for text in alist:\n",
    "    wordCountAns.update(text.strip(' .!?').split(' '))\n",
    "valueSortedAns = sorted(wordCountAns.values(), reverse=True)\n",
    "inverseDictrAns = dict(zip(wordCountAns.values(), wordCountAns.keys()))\n",
    "print(\"top 20 words\")\n",
    "print([[inverseDictrAns[v],v] for v in valueSortedAns[0:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When did Beyonce start becoming popular?',\n",
       " 'What areas did Beyonce compete in when she was growing up?',\n",
       " \"When did Beyonce leave Destiny's Child and become a solo singer?\",\n",
       " 'In what city and state did Beyonce  grow up? ',\n",
       " 'In which decade did Beyonce become famous?',\n",
       " 'In what R&B group was she the lead singer?',\n",
       " 'What album made her a worldwide known artist?',\n",
       " \"Who managed the Destiny's Child group?\",\n",
       " 'When did Beyoncé rise to fame?',\n",
       " \"What role did Beyoncé have in Destiny's Child?\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlist[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in the late 1990s',\n",
       " 'singing and dancing',\n",
       " '2003',\n",
       " 'Houston, Texas',\n",
       " 'late 1990s',\n",
       " \"Destiny's Child\",\n",
       " 'Dangerously in Love',\n",
       " 'Mathew Knowles',\n",
       " 'late 1990s',\n",
       " 'lead singer']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alist[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 4: text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "#import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "stopSet = set(stopwords.words('english'))\n",
    "stopSet.update({'-s','-ly','</s>','\\'s','\\'\\'', '\\''})\n",
    "\n",
    "#stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import math\n",
    "def textPreprocessing(text):\n",
    "    seg = []\n",
    "    for word in word_tokenize(text):\n",
    "        word = ps.stem(word.lower())\n",
    "        word = '#number' if word.isdigit() else word\n",
    "        if len(word) > 1 and word not in stopSet:\n",
    "            seg.append(word)\n",
    "    return seg\n",
    "\n",
    "wordsCount = Counter()\n",
    "preQList = []\n",
    "for text in qlist:\n",
    "    seg = textPreprocessing(text)\n",
    "    preQList.append(seg)\n",
    "    wordsCount.update(seg)\n",
    "\n",
    "valueSorted = sorted(wordsCount.values(), reverse=True)\n",
    "\n",
    "# delete low frequency words\n",
    "for cur in range(len(preQList)):\n",
    "    preQList[cur] = [word for word in preQList[cur] if wordsCount[word] > 7]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueSorted[int(0.20 * len(valueSorted))]\n",
    "# In the above code, we use 7 as the frequency threshold, which represents 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['beyonc', 'start', 'becom', 'popular'],\n",
       " ['area', 'beyonc', 'compet', 'wa', 'grow'],\n",
       " ['beyonc', 'leav', 'destini', 'child', 'becom', 'solo', 'singer'],\n",
       " ['citi', 'state', 'beyonc', 'grow'],\n",
       " ['decad', 'beyonc', 'becom', 'famou'],\n",
       " ['group', 'wa', 'lead', 'singer'],\n",
       " ['album', 'made', 'worldwid', 'known', 'artist'],\n",
       " ['manag', 'destini', 'child', 'group'],\n",
       " ['beyoncé', 'rise', 'fame'],\n",
       " ['role', 'beyoncé', 'destini', 'child']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preQList[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 5: word representation with tf-idf method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer =  TfidfVectorizer() \n",
    "\n",
    "X =  vectorizer.fit_transform([' '.join(seg) for seg in preQList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09614641890224648%\n"
     ]
    }
   ],
   "source": [
    "sparsity =  X.nnz/float(X.shape[0] * X.shape[1]) * 100\n",
    "print(str(sparsity) + '%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 6: find the top 5 answers to a testing question by comparing the testing question's cosine similarity with the questions in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from queue import PriorityQueue\n",
    "def top5results(input_q):\n",
    "    qVector = vectorizer.transform([' '.join(textPreprocessing(input_q))])\n",
    "    pq = PriorityQueue()\n",
    "    sim = (X * qVector.T).toarray()\n",
    "\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        pq.put((sim[i][0],i))\n",
    "        if len(pq.queue) > 5:\n",
    "            pq.get()\n",
    "    pq_rank = sorted(pq.queue, reverse=True, key=lambda x:x[0])\n",
    "    \n",
    "    top_idxs = [x[1] for x in pq_rank]  \n",
    "                  \n",
    "\n",
    "    return [alist[i] for i in top_idxs]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chengdu Shuangliu International Airport', 'Chengdu Shuangliu International Airport', '1991', '1985', 'aerodrome with facilities for flights to take off and land']\n",
      "['Plymouth City Airport', 'aerodrome with facilities for flights to take off and land', 'May 12', 'After the reunification', 'related']\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(top5results(\"Which airport was shut down?\")) \n",
    "print(top5results(\"Which airport is closed?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time complexity: O(ND)， space complexity: O(ND)\n",
    "N refers to the number of questions in the data set\n",
    "D refers to the size of the dictionary\n",
    "We calculate the cosin-similarity with the D time complexity\n",
    "Comparing the querried question with all N questions in data set is in time complexity N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 7: apply the inverted index to decrease the time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "inverted_idx = defaultdict(set)\n",
    "for cur in range(len(preQList)):\n",
    "    for word in preQList[cur]:\n",
    "        inverted_idx[word].add(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 21,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 58,\n",
       " 63,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 78,\n",
       " 79,\n",
       " 83,\n",
       " 89,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 101,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 115,\n",
       " 117,\n",
       " 125,\n",
       " 126,\n",
       " 128,\n",
       " 130,\n",
       " 131,\n",
       " 141,\n",
       " 149,\n",
       " 153,\n",
       " 154,\n",
       " 160,\n",
       " 161,\n",
       " 163,\n",
       " 164,\n",
       " 166,\n",
       " 167,\n",
       " 173,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 179,\n",
       " 180,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 209,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 233,\n",
       " 238,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 244,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 255,\n",
       " 265,\n",
       " 266,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 281,\n",
       " 283,\n",
       " 289,\n",
       " 290,\n",
       " 292,\n",
       " 293,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 309,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 329,\n",
       " 330,\n",
       " 336,\n",
       " 337,\n",
       " 350,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 379,\n",
       " 381,\n",
       " 383,\n",
       " 391,\n",
       " 392,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 403,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 433,\n",
       " 435,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 485,\n",
       " 486,\n",
       " 489,\n",
       " 492,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 578,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 606,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 615,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 650,\n",
       " 652,\n",
       " 655,\n",
       " 657,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 674,\n",
       " 677,\n",
       " 683,\n",
       " 685,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 714,\n",
       " 715,\n",
       " 717,\n",
       " 722,\n",
       " 723,\n",
       " 725,\n",
       " 726,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 745}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_idx['beyonc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5results_invidx(input_q):\n",
    "    preInputQ = textPreprocessing(input_q)\n",
    "    candidate = set()\n",
    "    for word in preInputQ:\n",
    "        candidate = candidate | inverted_idx[word]\n",
    "    candidate = list(candidate)\n",
    "    \n",
    "    qVector = vectorizer.transform([' '.join(preInputQ)])\n",
    "    sim = (X[candidate] * qVector.T).toarray()\n",
    "    pq = PriorityQueue()\n",
    "    for cur in range(sim.shape[0]):\n",
    "        pq.put((sim[cur][0], candidate[cur]))\n",
    "        if len(pq.queue) > 5:\n",
    "            pq.get()\n",
    "    pq_rank = sorted(pq.queue, reverse=True, key=lambda x: x[0])\n",
    "    top_idxs = [x[1] for x in pq_rank]\n",
    "    return [alist[i] for i in top_idxs]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chengdu Shuangliu International Airport', 'Chengdu Shuangliu International Airport', '1991', '1985', 'aerodrome with facilities for flights to take off and land']\n",
      "['Plymouth City Airport', 'May 12', 'aerodrome with facilities for flights to take off and land', 'After the reunification', 'related']\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(top5results_invidx(\"Which airport was shut down?\"))    # 在问题库中存在，经过对比，返回的首结果正确\n",
    "print(top5results_invidx(\"Which airport is closed?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time complexity: O(ND)， space complexity: O(ND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 8: replace the tf-idf word representation with the word2vec method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above part, we use the bag-of-words model. But this model can not consider the similarity between words and the representation vector is sparse. In the following part, we use the word2vec model with glove.6B.100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-29e519ee869c>:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  vector += model.wv[word]\n",
      "<ipython-input-37-29e519ee869c>:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return vector / size\n"
     ]
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "_ = glove2word2vec('data/glove.6B.100d.txt','data/glove2word2vec.6B.100d.txt')\n",
    "model = KeyedVectors.load_word2vec_format('data/glove2word2vec.6B.100d.txt')\n",
    "def docvec_get(seg):\n",
    "    # change the words in preQlist into vector\n",
    "    vector = np.zeros([1,100])\n",
    "    size = len(seg)\n",
    "    for word in seg:\n",
    "        try:\n",
    "            vector += model.wv[word]\n",
    "        except KeyError:\n",
    "            size -= 1\n",
    "    return vector / size\n",
    "X = np.zeros([len(preQList), 100])\n",
    "for cur in range(X.shape[0]):\n",
    "    X[cur] = docvec_get(preQList[cur])\n",
    "Xnorm2 = np.linalg.norm(X,axis=1,keepdims=True)\n",
    "X/=Xnorm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5results_emb(input_q):\n",
    "    seg = textPreprocessing(input_q)\n",
    "    candidate = set()\n",
    "    for word in seg:\n",
    "        candidate = candidate | inverted_idx[word]\n",
    "    candidate = list(candidate)\n",
    "    qVector = docvec_get(seg)\n",
    "    qnorm2 = np.linalg.norm(qVector,axis=1,keepdims=True)\n",
    "    qVector/=qnorm2\n",
    "   \n",
    "    sim = (X[candidate] @ qVector.T)\n",
    "  \n",
    "    pq = PriorityQueue()\n",
    "    for cur in range(sim.shape[0]):\n",
    "        pq.put((sim[cur][0],candidate[cur]))\n",
    "        if len(pq.queue) > 5:\n",
    "            pq.get()\n",
    "    pq_rank = sorted(pq.queue, reverse=True, key=lambda x: x[0])\n",
    "    print([x[0] for x in pq_rank])\n",
    "    top_idxs = [x[1] for x in pq_rank]\n",
    "    return [alist[i] for i in top_idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.8980219398331406, 0.8875869259222657, 0.8826214612899687]\n",
      "['Chengdu Shuangliu International Airport', 'Chengdu Shuangliu International Airport', 'Impregilo', 'Terminal C', 'Nanjing Dajiaochang Airport']\n",
      "[0.9454294862808651, 0.897533314447132, 0.8921468921909476, 0.8917413888585661, 0.8866939369431388]\n",
      "['Plymouth City Airport', 'Norwood Memorial Airport', 'Beverly Municipal Airport', 'Dushanbe International Airport', 'Lukou International Airport']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-29e519ee869c>:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  vector += model.wv[word]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(top5results_emb(\"Which airport was shut down?\"))\n",
    "print(top5results_emb(\"Which airport is closed?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
